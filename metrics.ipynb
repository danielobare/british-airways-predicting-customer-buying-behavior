{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb55247d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "df = pd.read_csv(\"creditcard.csv\")[:80_000]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f7a2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shapes of X=(80000, 28) y=(80000,), #Fraud Cases=196'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['Time', 'Amount', 'Class']).values\n",
    "y = df['Class'].values\n",
    "f\"Shapes of X={X.shape} y={y.shape}, #Fraud Cases={y.sum()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c199a45f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mod = LogisticRegression(class_weight={0: 1, 1: 2}, max_iter=1000)\n",
    "mod.fit(X, y).predict(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4051fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "??lr.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3590121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: 1.0},\n",
       "                                          {0: 1, 1: 1.6551724137931034},\n",
       "                                          {0: 1, 1: 2.310344827586207},\n",
       "                                          {0: 1, 1: 2.9655172413793105},\n",
       "                                          {0: 1, 1: 3.6206896551724137},\n",
       "                                          {0: 1, 1: 4.275862068965517},\n",
       "                                          {0: 1, 1: 4.931034482758621},\n",
       "                                          {0: 1, 1: 5.586206896551724},\n",
       "                                          {0: 1, 1: 6.241379310344827},\n",
       "                                          {0: 1, 1: 6.896551724137931},...\n",
       "                                          {0: 1, 1: 14.758620689655173},\n",
       "                                          {0: 1, 1: 15.413793103448276},\n",
       "                                          {0: 1, 1: 16.06896551724138},\n",
       "                                          {0: 1, 1: 16.724137931034484},\n",
       "                                          {0: 1, 1: 17.379310344827587},\n",
       "                                          {0: 1, 1: 18.03448275862069},\n",
       "                                          {0: 1, 1: 18.689655172413794},\n",
       "                                          {0: 1, 1: 19.344827586206897},\n",
       "                                          {0: 1, 1: 20.0}]},\n",
       "             refit=&#x27;precision&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;precision&#x27;: make_scorer(precision_score),\n",
       "                      &#x27;recall_score&#x27;: make_scorer(recall_score)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: 1.0},\n",
       "                                          {0: 1, 1: 1.6551724137931034},\n",
       "                                          {0: 1, 1: 2.310344827586207},\n",
       "                                          {0: 1, 1: 2.9655172413793105},\n",
       "                                          {0: 1, 1: 3.6206896551724137},\n",
       "                                          {0: 1, 1: 4.275862068965517},\n",
       "                                          {0: 1, 1: 4.931034482758621},\n",
       "                                          {0: 1, 1: 5.586206896551724},\n",
       "                                          {0: 1, 1: 6.241379310344827},\n",
       "                                          {0: 1, 1: 6.896551724137931},...\n",
       "                                          {0: 1, 1: 14.758620689655173},\n",
       "                                          {0: 1, 1: 15.413793103448276},\n",
       "                                          {0: 1, 1: 16.06896551724138},\n",
       "                                          {0: 1, 1: 16.724137931034484},\n",
       "                                          {0: 1, 1: 17.379310344827587},\n",
       "                                          {0: 1, 1: 18.03448275862069},\n",
       "                                          {0: 1, 1: 18.689655172413794},\n",
       "                                          {0: 1, 1: 19.344827586206897},\n",
       "                                          {0: 1, 1: 20.0}]},\n",
       "             refit=&#x27;precision&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;precision&#x27;: make_scorer(precision_score),\n",
       "                      &#x27;recall_score&#x27;: make_scorer(recall_score)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 1, 1: 1.0},\n",
       "                                          {0: 1, 1: 1.6551724137931034},\n",
       "                                          {0: 1, 1: 2.310344827586207},\n",
       "                                          {0: 1, 1: 2.9655172413793105},\n",
       "                                          {0: 1, 1: 3.6206896551724137},\n",
       "                                          {0: 1, 1: 4.275862068965517},\n",
       "                                          {0: 1, 1: 4.931034482758621},\n",
       "                                          {0: 1, 1: 5.586206896551724},\n",
       "                                          {0: 1, 1: 6.241379310344827},\n",
       "                                          {0: 1, 1: 6.896551724137931},...\n",
       "                                          {0: 1, 1: 14.758620689655173},\n",
       "                                          {0: 1, 1: 15.413793103448276},\n",
       "                                          {0: 1, 1: 16.06896551724138},\n",
       "                                          {0: 1, 1: 16.724137931034484},\n",
       "                                          {0: 1, 1: 17.379310344827587},\n",
       "                                          {0: 1, 1: 18.03448275862069},\n",
       "                                          {0: 1, 1: 18.689655172413794},\n",
       "                                          {0: 1, 1: 19.344827586206897},\n",
       "                                          {0: 1, 1: 20.0}]},\n",
       "             refit='precision', return_train_score=True,\n",
       "             scoring={'precision': make_scorer(precision_score),\n",
       "                      'recall_score': make_scorer(recall_score)})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator = LogisticRegression(max_iter=1000),\n",
    "    param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace (1, 20, 30)]},\n",
    "    scoring={'precision': make_scorer(precision_score), 'recall_score': make_scorer(recall_score)}, \n",
    "    refit = 'precision',\n",
    "    return_train_score=True,\n",
    "    cv = 10,\n",
    "    n_jobs = -1\n",
    ")\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444cdf4f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.25329273, 2.27790389, 2.23323812, 2.2865097 , 1.9832376 ,\n",
       "        2.22665834, 2.36122005, 2.27303507, 2.24202998, 2.48400667,\n",
       "        2.2269479 , 2.22037094, 2.10040367, 2.22826748, 2.11302211,\n",
       "        2.09930232, 2.14891469, 2.12790356, 2.25552044, 2.31666498,\n",
       "        2.17687933, 2.24095075, 2.10560982, 2.59087341, 2.6941654 ,\n",
       "        2.02329884, 2.23499794, 2.26342983, 2.10263088, 2.06769166]),\n",
       " 'std_fit_time': array([0.25929585, 0.35856549, 0.19149527, 0.23718132, 0.26369522,\n",
       "        0.29752443, 0.26942522, 0.31151026, 0.23015105, 0.50261382,\n",
       "        0.27150304, 0.24688955, 0.26183174, 0.39149623, 0.31174542,\n",
       "        0.33649426, 0.13332707, 0.20527122, 0.24954662, 0.24994735,\n",
       "        0.26600773, 0.23068892, 0.16477237, 0.63567697, 0.30741828,\n",
       "        0.27220509, 0.32796546, 0.29052956, 0.22049774, 0.22374875]),\n",
       " 'mean_score_time': array([0.02273827, 0.02473357, 0.0197484 , 0.01874771, 0.02683058,\n",
       "        0.02054586, 0.02978001, 0.02608986, 0.02623303, 0.02692811,\n",
       "        0.05261164, 0.0238328 , 0.01844866, 0.02802393, 0.03754551,\n",
       "        0.03550105, 0.02543366, 0.02763855, 0.03241341, 0.04922457,\n",
       "        0.02293925, 0.02623332, 0.02573271, 0.06941686, 0.03590548,\n",
       "        0.02992291, 0.02459941, 0.0300184 , 0.04222746, 0.02044525]),\n",
       " 'std_score_time': array([0.00838963, 0.00851911, 0.00647692, 0.00308398, 0.00814674,\n",
       "        0.00411525, 0.01185213, 0.0078811 , 0.01168059, 0.0121325 ,\n",
       "        0.03525957, 0.0108875 , 0.00343527, 0.01546057, 0.02747007,\n",
       "        0.02031486, 0.00839454, 0.0094824 , 0.01553425, 0.02876462,\n",
       "        0.00790328, 0.01138347, 0.00935303, 0.04221616, 0.02624192,\n",
       "        0.01192965, 0.0106916 , 0.01359665, 0.0255935 , 0.00698456]),\n",
       " 'param_class_weight': masked_array(data=[{0: 1, 1: 1.0}, {0: 1, 1: 1.6551724137931034},\n",
       "                    {0: 1, 1: 2.310344827586207},\n",
       "                    {0: 1, 1: 2.9655172413793105},\n",
       "                    {0: 1, 1: 3.6206896551724137},\n",
       "                    {0: 1, 1: 4.275862068965517},\n",
       "                    {0: 1, 1: 4.931034482758621},\n",
       "                    {0: 1, 1: 5.586206896551724},\n",
       "                    {0: 1, 1: 6.241379310344827},\n",
       "                    {0: 1, 1: 6.896551724137931},\n",
       "                    {0: 1, 1: 7.551724137931034},\n",
       "                    {0: 1, 1: 8.206896551724139},\n",
       "                    {0: 1, 1: 8.862068965517242},\n",
       "                    {0: 1, 1: 9.517241379310345},\n",
       "                    {0: 1, 1: 10.172413793103448},\n",
       "                    {0: 1, 1: 10.827586206896552},\n",
       "                    {0: 1, 1: 11.482758620689655},\n",
       "                    {0: 1, 1: 12.137931034482758},\n",
       "                    {0: 1, 1: 12.793103448275861},\n",
       "                    {0: 1, 1: 13.448275862068964},\n",
       "                    {0: 1, 1: 14.103448275862068},\n",
       "                    {0: 1, 1: 14.758620689655173},\n",
       "                    {0: 1, 1: 15.413793103448276},\n",
       "                    {0: 1, 1: 16.06896551724138},\n",
       "                    {0: 1, 1: 16.724137931034484},\n",
       "                    {0: 1, 1: 17.379310344827587},\n",
       "                    {0: 1, 1: 18.03448275862069},\n",
       "                    {0: 1, 1: 18.689655172413794},\n",
       "                    {0: 1, 1: 19.344827586206897}, {0: 1, 1: 20.0}],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'class_weight': {0: 1, 1: 1.0}},\n",
       "  {'class_weight': {0: 1, 1: 1.6551724137931034}},\n",
       "  {'class_weight': {0: 1, 1: 2.310344827586207}},\n",
       "  {'class_weight': {0: 1, 1: 2.9655172413793105}},\n",
       "  {'class_weight': {0: 1, 1: 3.6206896551724137}},\n",
       "  {'class_weight': {0: 1, 1: 4.275862068965517}},\n",
       "  {'class_weight': {0: 1, 1: 4.931034482758621}},\n",
       "  {'class_weight': {0: 1, 1: 5.586206896551724}},\n",
       "  {'class_weight': {0: 1, 1: 6.241379310344827}},\n",
       "  {'class_weight': {0: 1, 1: 6.896551724137931}},\n",
       "  {'class_weight': {0: 1, 1: 7.551724137931034}},\n",
       "  {'class_weight': {0: 1, 1: 8.206896551724139}},\n",
       "  {'class_weight': {0: 1, 1: 8.862068965517242}},\n",
       "  {'class_weight': {0: 1, 1: 9.517241379310345}},\n",
       "  {'class_weight': {0: 1, 1: 10.172413793103448}},\n",
       "  {'class_weight': {0: 1, 1: 10.827586206896552}},\n",
       "  {'class_weight': {0: 1, 1: 11.482758620689655}},\n",
       "  {'class_weight': {0: 1, 1: 12.137931034482758}},\n",
       "  {'class_weight': {0: 1, 1: 12.793103448275861}},\n",
       "  {'class_weight': {0: 1, 1: 13.448275862068964}},\n",
       "  {'class_weight': {0: 1, 1: 14.103448275862068}},\n",
       "  {'class_weight': {0: 1, 1: 14.758620689655173}},\n",
       "  {'class_weight': {0: 1, 1: 15.413793103448276}},\n",
       "  {'class_weight': {0: 1, 1: 16.06896551724138}},\n",
       "  {'class_weight': {0: 1, 1: 16.724137931034484}},\n",
       "  {'class_weight': {0: 1, 1: 17.379310344827587}},\n",
       "  {'class_weight': {0: 1, 1: 18.03448275862069}},\n",
       "  {'class_weight': {0: 1, 1: 18.689655172413794}},\n",
       "  {'class_weight': {0: 1, 1: 19.344827586206897}},\n",
       "  {'class_weight': {0: 1, 1: 20.0}}],\n",
       " 'split0_test_precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.89473684, 0.85      ,\n",
       "        0.85      , 0.85714286, 0.85714286, 0.85714286, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ]),\n",
       " 'split1_test_precision': array([0.46341463, 0.46341463, 0.46341463, 0.45238095, 0.45238095,\n",
       "        0.45238095, 0.45238095, 0.45238095, 0.45238095, 0.45238095,\n",
       "        0.45238095, 0.45238095, 0.44186047, 0.43181818, 0.43181818,\n",
       "        0.43181818, 0.43181818, 0.43181818, 0.41304348, 0.41304348,\n",
       "        0.41304348, 0.40425532, 0.3877551 , 0.38      , 0.38      ,\n",
       "        0.38      , 0.36538462, 0.34545455, 0.34545455, 0.33928571]),\n",
       " 'split2_test_precision': array([0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "        0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "        0.58333333, 0.58333333, 0.58333333, 0.56      , 0.56      ,\n",
       "        0.56      , 0.56      , 0.57692308, 0.57692308, 0.57692308,\n",
       "        0.57692308, 0.57692308, 0.57692308, 0.57692308, 0.55555556,\n",
       "        0.55555556, 0.53571429, 0.53571429, 0.53571429, 0.53571429]),\n",
       " 'split3_test_precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842]),\n",
       " 'split4_test_precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.92307692,\n",
       "        0.92307692, 0.92307692, 0.86666667, 0.86666667, 0.86666667]),\n",
       " 'split5_test_precision': array([0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.89473684, 0.89473684, 0.85      ,\n",
       "        0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "        0.85      , 0.85      , 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182]),\n",
       " 'split6_test_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split7_test_precision': array([0.81818182, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
       "        0.83333333, 0.84615385, 0.85714286, 0.875     , 0.875     ,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
       "        0.875     , 0.88235294, 0.88235294, 0.88235294, 0.88235294,\n",
       "        0.88235294, 0.88235294, 0.88235294, 0.88235294, 0.83333333,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.75      , 0.71428571]),\n",
       " 'split8_test_precision': array([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split9_test_precision': array([1.        , 1.        , 1.        , 1.        , 0.92857143,\n",
       "        0.93333333, 0.94117647, 0.94117647, 0.94117647, 0.94117647,\n",
       "        0.94117647, 0.94117647, 0.94117647, 0.94117647, 0.94117647,\n",
       "        0.94117647, 0.94117647, 0.94117647, 0.88888889, 0.88888889,\n",
       "        0.88888889, 0.84210526, 0.84210526, 0.84210526, 0.8       ,\n",
       "        0.8       , 0.8       , 0.8       , 0.8       , 0.8       ]),\n",
       " 'mean_test_precision': array([0.78093742, 0.88245257, 0.88245257, 0.88134921, 0.87420635,\n",
       "        0.87468254, 0.8767489 , 0.87287705, 0.86384405, 0.85937036,\n",
       "        0.85937036, 0.85937036, 0.85831831, 0.85000999, 0.84553631,\n",
       "        0.84553631, 0.84698589, 0.84939248, 0.84228625, 0.83839015,\n",
       "        0.83839015, 0.83283297, 0.83118295, 0.82295402, 0.80401247,\n",
       "        0.79962651, 0.79618084, 0.78854681, 0.78459944, 0.78041113]),\n",
       " 'std_test_precision': array([0.31902901, 0.18820871, 0.18820871, 0.19067822, 0.18740959,\n",
       "        0.18755312, 0.18756457, 0.18623748, 0.18003759, 0.17976999,\n",
       "        0.17976999, 0.17976999, 0.18216354, 0.18625149, 0.18565978,\n",
       "        0.18565978, 0.18581622, 0.18327189, 0.18562023, 0.18567639,\n",
       "        0.18567639, 0.18693992, 0.19074947, 0.19282111, 0.18830869,\n",
       "        0.18808533, 0.19395897, 0.19546163, 0.19580135, 0.19809322]),\n",
       " 'rank_test_precision': array([29,  1,  1,  3,  6,  5,  4,  7,  8,  9,  9,  9, 12, 13, 16, 16, 15,\n",
       "        14, 18, 19, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30]),\n",
       " 'split0_train_precision': array([0.80434783, 0.76821192, 0.77848101, 0.77639752, 0.79041916,\n",
       "        0.79411765, 0.80225989, 0.80446927, 0.81111111, 0.80978261,\n",
       "        0.80978261, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
       "        0.80645161, 0.80748663, 0.80319149, 0.80319149, 0.80319149,\n",
       "        0.80319149, 0.79581152, 0.79581152, 0.79166667, 0.79166667,\n",
       "        0.79166667, 0.79166667, 0.79166667, 0.78350515, 0.78571429]),\n",
       " 'split1_train_precision': array([0.91724138, 0.92307692, 0.91975309, 0.91975309, 0.92073171,\n",
       "        0.92073171, 0.92073171, 0.91071429, 0.90532544, 0.89473684,\n",
       "        0.89473684, 0.88953488, 0.88953488, 0.87931034, 0.87931034,\n",
       "        0.87931034, 0.87428571, 0.875     , 0.8700565 , 0.86516854,\n",
       "        0.8603352 , 0.85555556, 0.84615385, 0.84615385, 0.82795699,\n",
       "        0.82795699, 0.81914894, 0.81052632, 0.79381443, 0.78571429]),\n",
       " 'split2_train_precision': array([0.84090909, 0.82876712, 0.83974359, 0.84756098, 0.84883721,\n",
       "        0.84659091, 0.84745763, 0.84745763, 0.83798883, 0.83888889,\n",
       "        0.83977901, 0.83977901, 0.84153005, 0.83695652, 0.83243243,\n",
       "        0.83243243, 0.82795699, 0.82887701, 0.82539683, 0.82539683,\n",
       "        0.81675393, 0.80829016, 0.80412371, 0.79187817, 0.7839196 ,\n",
       "        0.77227723, 0.76470588, 0.76097561, 0.75728155, 0.75728155]),\n",
       " 'split3_train_precision': array([0.7578125 , 0.76551724, 0.77564103, 0.78125   , 0.78915663,\n",
       "        0.79532164, 0.80225989, 0.80446927, 0.80662983, 0.80769231,\n",
       "        0.80978261, 0.80978261, 0.80978261, 0.80540541, 0.80107527,\n",
       "        0.79679144, 0.79679144, 0.79473684, 0.79473684, 0.79581152,\n",
       "        0.79581152, 0.79166667, 0.78756477, 0.78756477, 0.78756477,\n",
       "        0.78461538, 0.77272727, 0.77272727, 0.76884422, 0.76884422]),\n",
       " 'split4_train_precision': array([0.7593985 , 0.77631579, 0.78616352, 0.79393939, 0.79166667,\n",
       "        0.79651163, 0.79885057, 0.8021978 , 0.80540541, 0.80540541,\n",
       "        0.80645161, 0.80748663, 0.80748663, 0.80748663, 0.80748663,\n",
       "        0.80319149, 0.8042328 , 0.80104712, 0.80104712, 0.80104712,\n",
       "        0.79792746, 0.79792746, 0.79792746, 0.78974359, 0.78974359,\n",
       "        0.78974359, 0.77777778, 0.76237624, 0.75490196, 0.75121951]),\n",
       " 'split5_train_precision': array([0.74814815, 0.77027027, 0.78343949, 0.79141104, 0.79393939,\n",
       "        0.80346821, 0.81355932, 0.81111111, 0.8121547 , 0.8121547 ,\n",
       "        0.81318681, 0.81420765, 0.81420765, 0.80978261, 0.81081081,\n",
       "        0.80645161, 0.80213904, 0.80213904, 0.80213904, 0.7989418 ,\n",
       "        0.7989418 , 0.79473684, 0.79166667, 0.79166667, 0.79166667,\n",
       "        0.79166667, 0.79166667, 0.79381443, 0.79381443, 0.78974359]),\n",
       " 'split6_train_precision': array([0.73880597, 0.76027397, 0.77564103, 0.7826087 , 0.78527607,\n",
       "        0.79532164, 0.80113636, 0.79888268, 0.80110497, 0.8021978 ,\n",
       "        0.80327869, 0.80327869, 0.79459459, 0.79459459, 0.79459459,\n",
       "        0.79459459, 0.79144385, 0.78723404, 0.78835979, 0.78947368,\n",
       "        0.78534031, 0.78125   , 0.78125   , 0.78125   , 0.77319588,\n",
       "        0.76923077, 0.76530612, 0.76262626, 0.74752475, 0.74384236]),\n",
       " 'split7_train_precision': array([0.76595745, 0.78571429, 0.79245283, 0.80120482, 0.80588235,\n",
       "        0.80813953, 0.81034483, 0.81142857, 0.81111111, 0.8121547 ,\n",
       "        0.8121547 , 0.80540541, 0.80645161, 0.8       , 0.79581152,\n",
       "        0.79581152, 0.79581152, 0.796875  , 0.79274611, 0.78865979,\n",
       "        0.78865979, 0.78461538, 0.78461538, 0.78461538, 0.78461538,\n",
       "        0.78061224, 0.77664975, 0.77272727, 0.75742574, 0.75742574]),\n",
       " 'split8_train_precision': array([0.76190476, 0.77848101, 0.78915663, 0.79532164, 0.79768786,\n",
       "        0.8       , 0.80446927, 0.80769231, 0.80748663, 0.80851064,\n",
       "        0.8042328 , 0.80104712, 0.80104712, 0.80104712, 0.796875  ,\n",
       "        0.79792746, 0.79896907, 0.79487179, 0.79591837, 0.78787879,\n",
       "        0.78787879, 0.78787879, 0.7839196 , 0.7839196 , 0.7839196 ,\n",
       "        0.7839196 , 0.785     , 0.78217822, 0.78217822, 0.78217822]),\n",
       " 'split9_train_precision': array([0.75352113, 0.77564103, 0.78527607, 0.78787879, 0.79289941,\n",
       "        0.79532164, 0.79885057, 0.80446927, 0.80662983, 0.80978261,\n",
       "        0.80978261, 0.80213904, 0.80319149, 0.80319149, 0.80319149,\n",
       "        0.7989418 , 0.79581152, 0.79581152, 0.79581152, 0.79581152,\n",
       "        0.79581152, 0.79581152, 0.79581152, 0.796875  , 0.79274611,\n",
       "        0.78974359, 0.78571429, 0.78172589, 0.78172589, 0.78172589]),\n",
       " 'mean_train_precision': array([0.78480467, 0.79322696, 0.80257483, 0.8077326 , 0.81164965,\n",
       "        0.81555245, 0.819992  , 0.82028922, 0.82049479, 0.82013065,\n",
       "        0.82031683, 0.81791126, 0.81742783, 0.81442263, 0.81280397,\n",
       "        0.81119043, 0.80949286, 0.80797839, 0.80694036, 0.80513811,\n",
       "        0.80306518, 0.79935439, 0.79688445, 0.79453337, 0.79069953,\n",
       "        0.78814327, 0.78303634, 0.77913442, 0.77210164, 0.77036897]),\n",
       " 'std_train_precision': array([0.05268875, 0.04690388, 0.04284959, 0.04182915, 0.04028248,\n",
       "        0.03810352, 0.03627198, 0.03282163, 0.02984173, 0.02662237,\n",
       "        0.02666218, 0.02613733, 0.02679795, 0.02416378, 0.02446424,\n",
       "        0.02499128, 0.023658  , 0.02466267, 0.02310217, 0.02249834,\n",
       "        0.02090023, 0.02005662, 0.01777753, 0.0177556 , 0.01356557,\n",
       "        0.01520361, 0.01513009, 0.01529442, 0.01616346, 0.01589423]),\n",
       " 'split0_test_recall_score': array([0.36842105, 0.42105263, 0.42105263, 0.63157895, 0.78947368,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842]),\n",
       " 'split1_test_recall_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_recall_score': array([0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
       "        0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
       "        0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
       "        0.73684211, 0.73684211, 0.78947368, 0.78947368, 0.78947368,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368]),\n",
       " 'split3_test_recall_score': array([0.47368421, 0.78947368, 0.84210526, 0.84210526, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842]),\n",
       " 'split4_test_recall_score': array([0.35, 0.35, 0.4 , 0.4 , 0.45, 0.45, 0.45, 0.45, 0.5 , 0.5 , 0.5 ,\n",
       "        0.5 , 0.5 , 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.6 , 0.6 , 0.6 ,\n",
       "        0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.65, 0.65, 0.65]),\n",
       " 'split5_test_recall_score': array([0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85,\n",
       "        0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.9 , 0.9 , 0.9 , 0.9 , 0.9 ,\n",
       "        0.9 , 0.9 , 0.9 , 0.9 , 0.9 , 0.9 , 0.9 , 0.9 ]),\n",
       " 'split6_test_recall_score': array([0.9 , 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 1.  , 1.  , 1.  , 1.  ,\n",
       "        1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "        1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ]),\n",
       " 'split7_test_recall_score': array([0.45, 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.55, 0.6 , 0.7 , 0.7 , 0.7 ,\n",
       "        0.7 , 0.7 , 0.7 , 0.7 , 0.7 , 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "        0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]),\n",
       " 'split8_test_recall_score': array([0.  , 0.25, 0.25, 0.25, 0.3 , 0.35, 0.35, 0.35, 0.4 , 0.5 , 0.5 ,\n",
       "        0.55, 0.6 , 0.6 , 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65,\n",
       "        0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65]),\n",
       " 'split9_test_recall_score': array([0.4 , 0.5 , 0.55, 0.65, 0.65, 0.7 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ,\n",
       "        0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ,\n",
       "        0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ]),\n",
       " 'mean_test_recall_score': array([0.55289474, 0.63473684, 0.65      , 0.68105263, 0.71210526,\n",
       "        0.73263158, 0.74763158, 0.76289474, 0.78289474, 0.79289474,\n",
       "        0.79289474, 0.79789474, 0.80289474, 0.80789474, 0.81289474,\n",
       "        0.81289474, 0.82315789, 0.83342105, 0.83342105, 0.83842105,\n",
       "        0.83842105, 0.83842105, 0.83842105, 0.83842105, 0.83842105,\n",
       "        0.83842105, 0.83842105, 0.84342105, 0.84342105, 0.84342105]),\n",
       " 'std_test_recall_score': array([0.29387433, 0.24991633, 0.24583793, 0.23079052, 0.22041324,\n",
       "        0.21599861, 0.21142718, 0.21642861, 0.19345685, 0.17512184,\n",
       "        0.17512184, 0.16722354, 0.16034265, 0.15134668, 0.14509262,\n",
       "        0.14509262, 0.14562312, 0.14487099, 0.14487099, 0.13556693,\n",
       "        0.13556693, 0.13556693, 0.13556693, 0.13556693, 0.13556693,\n",
       "        0.13556693, 0.13556693, 0.12735456, 0.12735456, 0.12735456]),\n",
       " 'rank_test_recall_score': array([30, 29, 28, 27, 26, 25, 24, 23, 22, 20, 20, 19, 18, 17, 15, 15, 14,\n",
       "        12, 12,  4,  4,  4,  4,  4,  4,  4,  4,  1,  1,  1]),\n",
       " 'split0_train_recall_score': array([0.62711864, 0.65536723, 0.69491525, 0.70621469, 0.74576271,\n",
       "        0.76271186, 0.80225989, 0.81355932, 0.82485876, 0.84180791,\n",
       "        0.84180791, 0.84745763, 0.84745763, 0.84745763, 0.84745763,\n",
       "        0.84745763, 0.85310734, 0.85310734, 0.85310734, 0.85310734,\n",
       "        0.85310734, 0.85875706, 0.85875706, 0.85875706, 0.85875706,\n",
       "        0.85875706, 0.85875706, 0.85875706, 0.85875706, 0.8700565 ]),\n",
       " 'split1_train_recall_score': array([0.75141243, 0.81355932, 0.84180791, 0.84180791, 0.85310734,\n",
       "        0.85310734, 0.85310734, 0.86440678, 0.86440678, 0.86440678,\n",
       "        0.86440678, 0.86440678, 0.86440678, 0.86440678, 0.86440678,\n",
       "        0.86440678, 0.86440678, 0.8700565 , 0.8700565 , 0.8700565 ,\n",
       "        0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 ,\n",
       "        0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 ]),\n",
       " 'split2_train_recall_score': array([0.62711864, 0.68361582, 0.74011299, 0.78531073, 0.82485876,\n",
       "        0.84180791, 0.84745763, 0.84745763, 0.84745763, 0.85310734,\n",
       "        0.85875706, 0.85875706, 0.8700565 , 0.8700565 , 0.8700565 ,\n",
       "        0.8700565 , 0.8700565 , 0.87570621, 0.88135593, 0.88135593,\n",
       "        0.88135593, 0.88135593, 0.88135593, 0.88135593, 0.88135593,\n",
       "        0.88135593, 0.88135593, 0.88135593, 0.88135593, 0.88135593]),\n",
       " 'split3_train_recall_score': array([0.5480226 , 0.62711864, 0.68361582, 0.70621469, 0.74011299,\n",
       "        0.76836158, 0.80225989, 0.81355932, 0.82485876, 0.83050847,\n",
       "        0.84180791, 0.84180791, 0.84180791, 0.84180791, 0.84180791,\n",
       "        0.84180791, 0.84180791, 0.85310734, 0.85310734, 0.85875706,\n",
       "        0.85875706, 0.85875706, 0.85875706, 0.85875706, 0.85875706,\n",
       "        0.86440678, 0.86440678, 0.86440678, 0.86440678, 0.86440678]),\n",
       " 'split4_train_recall_score': array([0.57386364, 0.67045455, 0.71022727, 0.74431818, 0.75568182,\n",
       "        0.77840909, 0.78977273, 0.82954545, 0.84659091, 0.84659091,\n",
       "        0.85227273, 0.85795455, 0.85795455, 0.85795455, 0.85795455,\n",
       "        0.85795455, 0.86363636, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ]),\n",
       " 'split5_train_recall_score': array([0.57386364, 0.64772727, 0.69886364, 0.73295455, 0.74431818,\n",
       "        0.78977273, 0.81818182, 0.82954545, 0.83522727, 0.83522727,\n",
       "        0.84090909, 0.84659091, 0.84659091, 0.84659091, 0.85227273,\n",
       "        0.85227273, 0.85227273, 0.85227273, 0.85227273, 0.85795455,\n",
       "        0.85795455, 0.85795455, 0.86363636, 0.86363636, 0.86363636,\n",
       "        0.86363636, 0.86363636, 0.875     , 0.875     , 0.875     ]),\n",
       " 'split6_train_recall_score': array([0.5625    , 0.63068182, 0.6875    , 0.71590909, 0.72727273,\n",
       "        0.77272727, 0.80113636, 0.8125    , 0.82386364, 0.82954545,\n",
       "        0.83522727, 0.83522727, 0.83522727, 0.83522727, 0.83522727,\n",
       "        0.83522727, 0.84090909, 0.84090909, 0.84659091, 0.85227273,\n",
       "        0.85227273, 0.85227273, 0.85227273, 0.85227273, 0.85227273,\n",
       "        0.85227273, 0.85227273, 0.85795455, 0.85795455, 0.85795455]),\n",
       " 'split7_train_recall_score': array([0.61363636, 0.6875    , 0.71590909, 0.75568182, 0.77840909,\n",
       "        0.78977273, 0.80113636, 0.80681818, 0.82954545, 0.83522727,\n",
       "        0.83522727, 0.84659091, 0.85227273, 0.86363636, 0.86363636,\n",
       "        0.86363636, 0.86363636, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.86931818, 0.86931818, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.86931818, 0.86931818, 0.86931818, 0.86931818, 0.86931818]),\n",
       " 'split8_train_recall_score': array([0.63636364, 0.69886364, 0.74431818, 0.77272727, 0.78409091,\n",
       "        0.79545455, 0.81818182, 0.83522727, 0.85795455, 0.86363636,\n",
       "        0.86363636, 0.86931818, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.875     , 0.88068182, 0.88068182, 0.88636364, 0.88636364,\n",
       "        0.88636364, 0.88636364, 0.88636364, 0.88636364, 0.88636364,\n",
       "        0.88636364, 0.89204545, 0.89772727, 0.89772727, 0.89772727]),\n",
       " 'split9_train_recall_score': array([0.60795455, 0.6875    , 0.72727273, 0.73863636, 0.76136364,\n",
       "        0.77272727, 0.78977273, 0.81818182, 0.82954545, 0.84659091,\n",
       "        0.84659091, 0.85227273, 0.85795455, 0.85795455, 0.85795455,\n",
       "        0.85795455, 0.86363636, 0.86363636, 0.86363636, 0.86363636,\n",
       "        0.86363636, 0.86363636, 0.86363636, 0.86931818, 0.86931818,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ]),\n",
       " 'mean_train_recall_score': array([0.61218541, 0.68023883, 0.72445429, 0.74997753, 0.77149782,\n",
       "        0.79248523, 0.81232666, 0.82708012, 0.83843092, 0.84466487,\n",
       "        0.84806433, 0.85203839, 0.8543047 , 0.85544106, 0.85600924,\n",
       "        0.85657743, 0.85941513, 0.86281138, 0.86451271, 0.86621405,\n",
       "        0.86678223, 0.8673472 , 0.86791538, 0.86848356, 0.86848356,\n",
       "        0.86961672, 0.8701849 , 0.87245763, 0.87245763, 0.87358757]),\n",
       " 'std_train_recall_score': array([0.05473334, 0.05028625, 0.04388149, 0.0395889 , 0.03795866,\n",
       "        0.02928924, 0.02106253, 0.01719007, 0.01397413, 0.01201522,\n",
       "        0.01050163, 0.00999687, 0.01110338, 0.01141441, 0.01109672,\n",
       "        0.01188135, 0.01177783, 0.01184309, 0.01253003, 0.01079785,\n",
       "        0.01109173, 0.01050939, 0.01013308, 0.01003605, 0.01003605,\n",
       "        0.00978859, 0.01085138, 0.01102546, 0.01102546, 0.01010396])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27008196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878787878787878"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y, grid.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16856142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_recall_score</th>\n",
       "      <th>split3_train_recall_score</th>\n",
       "      <th>split4_train_recall_score</th>\n",
       "      <th>split5_train_recall_score</th>\n",
       "      <th>split6_train_recall_score</th>\n",
       "      <th>split7_train_recall_score</th>\n",
       "      <th>split8_train_recall_score</th>\n",
       "      <th>split9_train_recall_score</th>\n",
       "      <th>mean_train_recall_score</th>\n",
       "      <th>std_train_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.253293</td>\n",
       "      <td>0.259296</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>{0: 1, 1: 1.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.0}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.548023</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.612185</td>\n",
       "      <td>0.054733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.277904</td>\n",
       "      <td>0.358565</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.008519</td>\n",
       "      <td>{0: 1, 1: 1.6551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.6551724137931034}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.630682</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.680239</td>\n",
       "      <td>0.050286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.233238</td>\n",
       "      <td>0.191495</td>\n",
       "      <td>0.019748</td>\n",
       "      <td>0.006477</td>\n",
       "      <td>{0: 1, 1: 2.310344827586207}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.310344827586207}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.724454</td>\n",
       "      <td>0.043881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.286510</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.018748</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>{0: 1, 1: 2.9655172413793105}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.9655172413793105}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.732955</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.749978</td>\n",
       "      <td>0.039589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.983238</td>\n",
       "      <td>0.263695</td>\n",
       "      <td>0.026831</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>{0: 1, 1: 3.6206896551724137}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3.6206896551724137}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.771498</td>\n",
       "      <td>0.037959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.226658</td>\n",
       "      <td>0.297524</td>\n",
       "      <td>0.020546</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>{0: 1, 1: 4.275862068965517}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.275862068965517}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.768362</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.792485</td>\n",
       "      <td>0.029289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.361220</td>\n",
       "      <td>0.269425</td>\n",
       "      <td>0.029780</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>{0: 1, 1: 4.931034482758621}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.931034482758621}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.812327</td>\n",
       "      <td>0.021063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.273035</td>\n",
       "      <td>0.311510</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>{0: 1, 1: 5.586206896551724}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 5.586206896551724}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.827080</td>\n",
       "      <td>0.017190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.242030</td>\n",
       "      <td>0.230151</td>\n",
       "      <td>0.026233</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>{0: 1, 1: 6.241379310344827}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.241379310344827}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.823864</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.838431</td>\n",
       "      <td>0.013974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.484007</td>\n",
       "      <td>0.502614</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>{0: 1, 1: 6.896551724137931}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.896551724137931}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.844665</td>\n",
       "      <td>0.012015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.226948</td>\n",
       "      <td>0.271503</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>0.035260</td>\n",
       "      <td>{0: 1, 1: 7.551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 7.551724137931034}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.848064</td>\n",
       "      <td>0.010502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.220371</td>\n",
       "      <td>0.246890</td>\n",
       "      <td>0.023833</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>{0: 1, 1: 8.206896551724139}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.206896551724139}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.852038</td>\n",
       "      <td>0.009997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.100404</td>\n",
       "      <td>0.261832</td>\n",
       "      <td>0.018449</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>{0: 1, 1: 8.862068965517242}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.862068965517242}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.011103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.228267</td>\n",
       "      <td>0.391496</td>\n",
       "      <td>0.028024</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>{0: 1, 1: 9.517241379310345}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 9.517241379310345}}</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.855441</td>\n",
       "      <td>0.011414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.113022</td>\n",
       "      <td>0.311745</td>\n",
       "      <td>0.037546</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>{0: 1, 1: 10.172413793103448}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.172413793103448}}</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.856009</td>\n",
       "      <td>0.011097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.099302</td>\n",
       "      <td>0.336494</td>\n",
       "      <td>0.035501</td>\n",
       "      <td>0.020315</td>\n",
       "      <td>{0: 1, 1: 10.827586206896552}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.827586206896552}}</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.856577</td>\n",
       "      <td>0.011881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.148915</td>\n",
       "      <td>0.133327</td>\n",
       "      <td>0.025434</td>\n",
       "      <td>0.008395</td>\n",
       "      <td>{0: 1, 1: 11.482758620689655}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 11.482758620689655}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.859415</td>\n",
       "      <td>0.011778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.127904</td>\n",
       "      <td>0.205271</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.009482</td>\n",
       "      <td>{0: 1, 1: 12.137931034482758}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.137931034482758}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.862811</td>\n",
       "      <td>0.011843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.255520</td>\n",
       "      <td>0.249547</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>0.015534</td>\n",
       "      <td>{0: 1, 1: 12.793103448275861}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.793103448275861}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.864513</td>\n",
       "      <td>0.012530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.316665</td>\n",
       "      <td>0.249947</td>\n",
       "      <td>0.049225</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>{0: 1, 1: 13.448275862068964}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 13.448275862068964}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.866214</td>\n",
       "      <td>0.010798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.176879</td>\n",
       "      <td>0.266008</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>{0: 1, 1: 14.103448275862068}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.103448275862068}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.866782</td>\n",
       "      <td>0.011092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.240951</td>\n",
       "      <td>0.230689</td>\n",
       "      <td>0.026233</td>\n",
       "      <td>0.011383</td>\n",
       "      <td>{0: 1, 1: 14.758620689655173}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.758620689655173}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.010509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.105610</td>\n",
       "      <td>0.164772</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>0.009353</td>\n",
       "      <td>{0: 1, 1: 15.413793103448276}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 15.413793103448276}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.867915</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.590873</td>\n",
       "      <td>0.635677</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.042216</td>\n",
       "      <td>{0: 1, 1: 16.06896551724138}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.06896551724138}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.010036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.694165</td>\n",
       "      <td>0.307418</td>\n",
       "      <td>0.035905</td>\n",
       "      <td>0.026242</td>\n",
       "      <td>{0: 1, 1: 16.724137931034484}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.724137931034484}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.010036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.023299</td>\n",
       "      <td>0.272205</td>\n",
       "      <td>0.029923</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>{0: 1, 1: 17.379310344827587}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 17.379310344827587}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869617</td>\n",
       "      <td>0.009789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.234998</td>\n",
       "      <td>0.327965</td>\n",
       "      <td>0.024599</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>{0: 1, 1: 18.03448275862069}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.03448275862069}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.870185</td>\n",
       "      <td>0.010851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.263430</td>\n",
       "      <td>0.290530</td>\n",
       "      <td>0.030018</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>{0: 1, 1: 18.689655172413794}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.689655172413794}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.872458</td>\n",
       "      <td>0.011025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.102631</td>\n",
       "      <td>0.220498</td>\n",
       "      <td>0.042227</td>\n",
       "      <td>0.025593</td>\n",
       "      <td>{0: 1, 1: 19.344827586206897}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 19.344827586206897}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.872458</td>\n",
       "      <td>0.011025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.067692</td>\n",
       "      <td>0.223749</td>\n",
       "      <td>0.020445</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>{0: 1, 1: 20.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 20.0}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873588</td>\n",
       "      <td>0.010104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.253293      0.259296         0.022738        0.008390   \n",
       "1        2.277904      0.358565         0.024734        0.008519   \n",
       "2        2.233238      0.191495         0.019748        0.006477   \n",
       "3        2.286510      0.237181         0.018748        0.003084   \n",
       "4        1.983238      0.263695         0.026831        0.008147   \n",
       "5        2.226658      0.297524         0.020546        0.004115   \n",
       "6        2.361220      0.269425         0.029780        0.011852   \n",
       "7        2.273035      0.311510         0.026090        0.007881   \n",
       "8        2.242030      0.230151         0.026233        0.011681   \n",
       "9        2.484007      0.502614         0.026928        0.012133   \n",
       "10       2.226948      0.271503         0.052612        0.035260   \n",
       "11       2.220371      0.246890         0.023833        0.010887   \n",
       "12       2.100404      0.261832         0.018449        0.003435   \n",
       "13       2.228267      0.391496         0.028024        0.015461   \n",
       "14       2.113022      0.311745         0.037546        0.027470   \n",
       "15       2.099302      0.336494         0.035501        0.020315   \n",
       "16       2.148915      0.133327         0.025434        0.008395   \n",
       "17       2.127904      0.205271         0.027639        0.009482   \n",
       "18       2.255520      0.249547         0.032413        0.015534   \n",
       "19       2.316665      0.249947         0.049225        0.028765   \n",
       "20       2.176879      0.266008         0.022939        0.007903   \n",
       "21       2.240951      0.230689         0.026233        0.011383   \n",
       "22       2.105610      0.164772         0.025733        0.009353   \n",
       "23       2.590873      0.635677         0.069417        0.042216   \n",
       "24       2.694165      0.307418         0.035905        0.026242   \n",
       "25       2.023299      0.272205         0.029923        0.011930   \n",
       "26       2.234998      0.327965         0.024599        0.010692   \n",
       "27       2.263430      0.290530         0.030018        0.013597   \n",
       "28       2.102631      0.220498         0.042227        0.025593   \n",
       "29       2.067692      0.223749         0.020445        0.006985   \n",
       "\n",
       "               param_class_weight  \\\n",
       "0                  {0: 1, 1: 1.0}   \n",
       "1   {0: 1, 1: 1.6551724137931034}   \n",
       "2    {0: 1, 1: 2.310344827586207}   \n",
       "3   {0: 1, 1: 2.9655172413793105}   \n",
       "4   {0: 1, 1: 3.6206896551724137}   \n",
       "5    {0: 1, 1: 4.275862068965517}   \n",
       "6    {0: 1, 1: 4.931034482758621}   \n",
       "7    {0: 1, 1: 5.586206896551724}   \n",
       "8    {0: 1, 1: 6.241379310344827}   \n",
       "9    {0: 1, 1: 6.896551724137931}   \n",
       "10   {0: 1, 1: 7.551724137931034}   \n",
       "11   {0: 1, 1: 8.206896551724139}   \n",
       "12   {0: 1, 1: 8.862068965517242}   \n",
       "13   {0: 1, 1: 9.517241379310345}   \n",
       "14  {0: 1, 1: 10.172413793103448}   \n",
       "15  {0: 1, 1: 10.827586206896552}   \n",
       "16  {0: 1, 1: 11.482758620689655}   \n",
       "17  {0: 1, 1: 12.137931034482758}   \n",
       "18  {0: 1, 1: 12.793103448275861}   \n",
       "19  {0: 1, 1: 13.448275862068964}   \n",
       "20  {0: 1, 1: 14.103448275862068}   \n",
       "21  {0: 1, 1: 14.758620689655173}   \n",
       "22  {0: 1, 1: 15.413793103448276}   \n",
       "23   {0: 1, 1: 16.06896551724138}   \n",
       "24  {0: 1, 1: 16.724137931034484}   \n",
       "25  {0: 1, 1: 17.379310344827587}   \n",
       "26   {0: 1, 1: 18.03448275862069}   \n",
       "27  {0: 1, 1: 18.689655172413794}   \n",
       "28  {0: 1, 1: 19.344827586206897}   \n",
       "29                {0: 1, 1: 20.0}   \n",
       "\n",
       "                                             params  split0_test_precision  \\\n",
       "0                  {'class_weight': {0: 1, 1: 1.0}}               1.000000   \n",
       "1   {'class_weight': {0: 1, 1: 1.6551724137931034}}               1.000000   \n",
       "2    {'class_weight': {0: 1, 1: 2.310344827586207}}               1.000000   \n",
       "3   {'class_weight': {0: 1, 1: 2.9655172413793105}}               1.000000   \n",
       "4   {'class_weight': {0: 1, 1: 3.6206896551724137}}               1.000000   \n",
       "5    {'class_weight': {0: 1, 1: 4.275862068965517}}               1.000000   \n",
       "6    {'class_weight': {0: 1, 1: 4.931034482758621}}               1.000000   \n",
       "7    {'class_weight': {0: 1, 1: 5.586206896551724}}               1.000000   \n",
       "8    {'class_weight': {0: 1, 1: 6.241379310344827}}               0.944444   \n",
       "9    {'class_weight': {0: 1, 1: 6.896551724137931}}               0.944444   \n",
       "10   {'class_weight': {0: 1, 1: 7.551724137931034}}               0.944444   \n",
       "11   {'class_weight': {0: 1, 1: 8.206896551724139}}               0.944444   \n",
       "12   {'class_weight': {0: 1, 1: 8.862068965517242}}               0.944444   \n",
       "13   {'class_weight': {0: 1, 1: 9.517241379310345}}               0.894737   \n",
       "14  {'class_weight': {0: 1, 1: 10.172413793103448}}               0.850000   \n",
       "15  {'class_weight': {0: 1, 1: 10.827586206896552}}               0.850000   \n",
       "16  {'class_weight': {0: 1, 1: 11.482758620689655}}               0.857143   \n",
       "17  {'class_weight': {0: 1, 1: 12.137931034482758}}               0.857143   \n",
       "18  {'class_weight': {0: 1, 1: 12.793103448275861}}               0.857143   \n",
       "19  {'class_weight': {0: 1, 1: 13.448275862068964}}               0.818182   \n",
       "20  {'class_weight': {0: 1, 1: 14.103448275862068}}               0.818182   \n",
       "21  {'class_weight': {0: 1, 1: 14.758620689655173}}               0.818182   \n",
       "22  {'class_weight': {0: 1, 1: 15.413793103448276}}               0.818182   \n",
       "23   {'class_weight': {0: 1, 1: 16.06896551724138}}               0.782609   \n",
       "24  {'class_weight': {0: 1, 1: 16.724137931034484}}               0.782609   \n",
       "25  {'class_weight': {0: 1, 1: 17.379310344827587}}               0.782609   \n",
       "26   {'class_weight': {0: 1, 1: 18.03448275862069}}               0.782609   \n",
       "27  {'class_weight': {0: 1, 1: 18.689655172413794}}               0.782609   \n",
       "28  {'class_weight': {0: 1, 1: 19.344827586206897}}               0.782609   \n",
       "29                {'class_weight': {0: 1, 1: 20.0}}               0.782609   \n",
       "\n",
       "    split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n",
       "0                0.463415               0.583333               1.000000  ...   \n",
       "1                0.463415               0.583333               1.000000  ...   \n",
       "2                0.463415               0.583333               1.000000  ...   \n",
       "3                0.452381               0.583333               1.000000  ...   \n",
       "4                0.452381               0.583333               1.000000  ...   \n",
       "5                0.452381               0.583333               1.000000  ...   \n",
       "6                0.452381               0.583333               1.000000  ...   \n",
       "7                0.452381               0.583333               1.000000  ...   \n",
       "8                0.452381               0.583333               0.947368  ...   \n",
       "9                0.452381               0.583333               0.947368  ...   \n",
       "10               0.452381               0.583333               0.947368  ...   \n",
       "11               0.452381               0.583333               0.947368  ...   \n",
       "12               0.441860               0.583333               0.947368  ...   \n",
       "13               0.431818               0.560000               0.947368  ...   \n",
       "14               0.431818               0.560000               0.947368  ...   \n",
       "15               0.431818               0.560000               0.947368  ...   \n",
       "16               0.431818               0.560000               0.947368  ...   \n",
       "17               0.431818               0.576923               0.947368  ...   \n",
       "18               0.413043               0.576923               0.947368  ...   \n",
       "19               0.413043               0.576923               0.947368  ...   \n",
       "20               0.413043               0.576923               0.947368  ...   \n",
       "21               0.404255               0.576923               0.947368  ...   \n",
       "22               0.387755               0.576923               0.947368  ...   \n",
       "23               0.380000               0.576923               0.947368  ...   \n",
       "24               0.380000               0.555556               0.947368  ...   \n",
       "25               0.380000               0.555556               0.947368  ...   \n",
       "26               0.365385               0.535714               0.947368  ...   \n",
       "27               0.345455               0.535714               0.947368  ...   \n",
       "28               0.345455               0.535714               0.947368  ...   \n",
       "29               0.339286               0.535714               0.947368  ...   \n",
       "\n",
       "    split2_train_recall_score  split3_train_recall_score  \\\n",
       "0                    0.627119                   0.548023   \n",
       "1                    0.683616                   0.627119   \n",
       "2                    0.740113                   0.683616   \n",
       "3                    0.785311                   0.706215   \n",
       "4                    0.824859                   0.740113   \n",
       "5                    0.841808                   0.768362   \n",
       "6                    0.847458                   0.802260   \n",
       "7                    0.847458                   0.813559   \n",
       "8                    0.847458                   0.824859   \n",
       "9                    0.853107                   0.830508   \n",
       "10                   0.858757                   0.841808   \n",
       "11                   0.858757                   0.841808   \n",
       "12                   0.870056                   0.841808   \n",
       "13                   0.870056                   0.841808   \n",
       "14                   0.870056                   0.841808   \n",
       "15                   0.870056                   0.841808   \n",
       "16                   0.870056                   0.841808   \n",
       "17                   0.875706                   0.853107   \n",
       "18                   0.881356                   0.853107   \n",
       "19                   0.881356                   0.858757   \n",
       "20                   0.881356                   0.858757   \n",
       "21                   0.881356                   0.858757   \n",
       "22                   0.881356                   0.858757   \n",
       "23                   0.881356                   0.858757   \n",
       "24                   0.881356                   0.858757   \n",
       "25                   0.881356                   0.864407   \n",
       "26                   0.881356                   0.864407   \n",
       "27                   0.881356                   0.864407   \n",
       "28                   0.881356                   0.864407   \n",
       "29                   0.881356                   0.864407   \n",
       "\n",
       "    split4_train_recall_score  split5_train_recall_score  \\\n",
       "0                    0.573864                   0.573864   \n",
       "1                    0.670455                   0.647727   \n",
       "2                    0.710227                   0.698864   \n",
       "3                    0.744318                   0.732955   \n",
       "4                    0.755682                   0.744318   \n",
       "5                    0.778409                   0.789773   \n",
       "6                    0.789773                   0.818182   \n",
       "7                    0.829545                   0.829545   \n",
       "8                    0.846591                   0.835227   \n",
       "9                    0.846591                   0.835227   \n",
       "10                   0.852273                   0.840909   \n",
       "11                   0.857955                   0.846591   \n",
       "12                   0.857955                   0.846591   \n",
       "13                   0.857955                   0.846591   \n",
       "14                   0.857955                   0.852273   \n",
       "15                   0.857955                   0.852273   \n",
       "16                   0.863636                   0.852273   \n",
       "17                   0.869318                   0.852273   \n",
       "18                   0.869318                   0.852273   \n",
       "19                   0.869318                   0.857955   \n",
       "20                   0.875000                   0.857955   \n",
       "21                   0.875000                   0.857955   \n",
       "22                   0.875000                   0.863636   \n",
       "23                   0.875000                   0.863636   \n",
       "24                   0.875000                   0.863636   \n",
       "25                   0.875000                   0.863636   \n",
       "26                   0.875000                   0.863636   \n",
       "27                   0.875000                   0.875000   \n",
       "28                   0.875000                   0.875000   \n",
       "29                   0.875000                   0.875000   \n",
       "\n",
       "    split6_train_recall_score  split7_train_recall_score  \\\n",
       "0                    0.562500                   0.613636   \n",
       "1                    0.630682                   0.687500   \n",
       "2                    0.687500                   0.715909   \n",
       "3                    0.715909                   0.755682   \n",
       "4                    0.727273                   0.778409   \n",
       "5                    0.772727                   0.789773   \n",
       "6                    0.801136                   0.801136   \n",
       "7                    0.812500                   0.806818   \n",
       "8                    0.823864                   0.829545   \n",
       "9                    0.829545                   0.835227   \n",
       "10                   0.835227                   0.835227   \n",
       "11                   0.835227                   0.846591   \n",
       "12                   0.835227                   0.852273   \n",
       "13                   0.835227                   0.863636   \n",
       "14                   0.835227                   0.863636   \n",
       "15                   0.835227                   0.863636   \n",
       "16                   0.840909                   0.863636   \n",
       "17                   0.840909                   0.869318   \n",
       "18                   0.846591                   0.869318   \n",
       "19                   0.852273                   0.869318   \n",
       "20                   0.852273                   0.869318   \n",
       "21                   0.852273                   0.869318   \n",
       "22                   0.852273                   0.869318   \n",
       "23                   0.852273                   0.869318   \n",
       "24                   0.852273                   0.869318   \n",
       "25                   0.852273                   0.869318   \n",
       "26                   0.852273                   0.869318   \n",
       "27                   0.857955                   0.869318   \n",
       "28                   0.857955                   0.869318   \n",
       "29                   0.857955                   0.869318   \n",
       "\n",
       "    split8_train_recall_score  split9_train_recall_score  \\\n",
       "0                    0.636364                   0.607955   \n",
       "1                    0.698864                   0.687500   \n",
       "2                    0.744318                   0.727273   \n",
       "3                    0.772727                   0.738636   \n",
       "4                    0.784091                   0.761364   \n",
       "5                    0.795455                   0.772727   \n",
       "6                    0.818182                   0.789773   \n",
       "7                    0.835227                   0.818182   \n",
       "8                    0.857955                   0.829545   \n",
       "9                    0.863636                   0.846591   \n",
       "10                   0.863636                   0.846591   \n",
       "11                   0.869318                   0.852273   \n",
       "12                   0.869318                   0.857955   \n",
       "13                   0.869318                   0.857955   \n",
       "14                   0.869318                   0.857955   \n",
       "15                   0.875000                   0.857955   \n",
       "16                   0.880682                   0.863636   \n",
       "17                   0.880682                   0.863636   \n",
       "18                   0.886364                   0.863636   \n",
       "19                   0.886364                   0.863636   \n",
       "20                   0.886364                   0.863636   \n",
       "21                   0.886364                   0.863636   \n",
       "22                   0.886364                   0.863636   \n",
       "23                   0.886364                   0.869318   \n",
       "24                   0.886364                   0.869318   \n",
       "25                   0.886364                   0.875000   \n",
       "26                   0.892045                   0.875000   \n",
       "27                   0.897727                   0.875000   \n",
       "28                   0.897727                   0.875000   \n",
       "29                   0.897727                   0.875000   \n",
       "\n",
       "    mean_train_recall_score  std_train_recall_score  \n",
       "0                  0.612185                0.054733  \n",
       "1                  0.680239                0.050286  \n",
       "2                  0.724454                0.043881  \n",
       "3                  0.749978                0.039589  \n",
       "4                  0.771498                0.037959  \n",
       "5                  0.792485                0.029289  \n",
       "6                  0.812327                0.021063  \n",
       "7                  0.827080                0.017190  \n",
       "8                  0.838431                0.013974  \n",
       "9                  0.844665                0.012015  \n",
       "10                 0.848064                0.010502  \n",
       "11                 0.852038                0.009997  \n",
       "12                 0.854305                0.011103  \n",
       "13                 0.855441                0.011414  \n",
       "14                 0.856009                0.011097  \n",
       "15                 0.856577                0.011881  \n",
       "16                 0.859415                0.011778  \n",
       "17                 0.862811                0.011843  \n",
       "18                 0.864513                0.012530  \n",
       "19                 0.866214                0.010798  \n",
       "20                 0.866782                0.011092  \n",
       "21                 0.867347                0.010509  \n",
       "22                 0.867915                0.010133  \n",
       "23                 0.868484                0.010036  \n",
       "24                 0.868484                0.010036  \n",
       "25                 0.869617                0.009789  \n",
       "26                 0.870185                0.010851  \n",
       "27                 0.872458                0.011025  \n",
       "28                 0.872458                0.011025  \n",
       "29                 0.873588                0.010104  \n",
       "\n",
       "[30 rows x 56 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23fe3b1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_test_recall'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_test_recall'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(grid\u001b[38;5;241m.\u001b[39mcv_results_)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_recall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_precision\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot([_[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_class_weight\u001b[39m\u001b[38;5;124m'\u001b[39m]], \n\u001b[1;32m----> 5\u001b[0m              \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m]\u001b[49m, \n\u001b[0;32m      6\u001b[0m              label\u001b[38;5;241m=\u001b[39mscore)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_test_recall'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "for score in ['mean_test_recall', 'mean_test_precision']:\n",
    "    plt.plot([_[1] for _ in df['param_class_weight']], \n",
    "             df[score], \n",
    "             label=score)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ecdd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
