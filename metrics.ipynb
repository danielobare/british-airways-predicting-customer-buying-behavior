{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb55247d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "df = pd.read_csv(\"creditcard.csv\")[:80_000]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f7a2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shapes of X=(80000, 28) y=(80000,), #Fraud Cases=196'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['Time', 'Amount', 'Class']).values\n",
    "y = df['Class'].values\n",
    "f\"Shapes of X={X.shape} y={y.shape}, #Fraud Cases={y.sum()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c199a45f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mod = LogisticRegression(class_weight={0: 1, 1: 2}, max_iter=1000)\n",
    "mod.fit(X, y).predict(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4051fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "??lr.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3590121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: 1.0},\n",
       "                                          {0: 1, 1: 1.6551724137931034},\n",
       "                                          {0: 1, 1: 2.310344827586207},\n",
       "                                          {0: 1, 1: 2.9655172413793105},\n",
       "                                          {0: 1, 1: 3.6206896551724137},\n",
       "                                          {0: 1, 1: 4.275862068965517},\n",
       "                                          {0: 1, 1: 4.931034482758621},\n",
       "                                          {0: 1, 1: 5.586206896551724},\n",
       "                                          {0: 1, 1: 6.241379310344827},\n",
       "                                          {0: 1, 1: 6.896551724137931},...\n",
       "                                          {0: 1, 1: 14.758620689655173},\n",
       "                                          {0: 1, 1: 15.413793103448276},\n",
       "                                          {0: 1, 1: 16.06896551724138},\n",
       "                                          {0: 1, 1: 16.724137931034484},\n",
       "                                          {0: 1, 1: 17.379310344827587},\n",
       "                                          {0: 1, 1: 18.03448275862069},\n",
       "                                          {0: 1, 1: 18.689655172413794},\n",
       "                                          {0: 1, 1: 19.344827586206897},\n",
       "                                          {0: 1, 1: 20.0}]},\n",
       "             refit=&#x27;precision&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;precision&#x27;: make_scorer(precision_score),\n",
       "                      &#x27;recall_score&#x27;: make_scorer(recall_score)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: 1.0},\n",
       "                                          {0: 1, 1: 1.6551724137931034},\n",
       "                                          {0: 1, 1: 2.310344827586207},\n",
       "                                          {0: 1, 1: 2.9655172413793105},\n",
       "                                          {0: 1, 1: 3.6206896551724137},\n",
       "                                          {0: 1, 1: 4.275862068965517},\n",
       "                                          {0: 1, 1: 4.931034482758621},\n",
       "                                          {0: 1, 1: 5.586206896551724},\n",
       "                                          {0: 1, 1: 6.241379310344827},\n",
       "                                          {0: 1, 1: 6.896551724137931},...\n",
       "                                          {0: 1, 1: 14.758620689655173},\n",
       "                                          {0: 1, 1: 15.413793103448276},\n",
       "                                          {0: 1, 1: 16.06896551724138},\n",
       "                                          {0: 1, 1: 16.724137931034484},\n",
       "                                          {0: 1, 1: 17.379310344827587},\n",
       "                                          {0: 1, 1: 18.03448275862069},\n",
       "                                          {0: 1, 1: 18.689655172413794},\n",
       "                                          {0: 1, 1: 19.344827586206897},\n",
       "                                          {0: 1, 1: 20.0}]},\n",
       "             refit=&#x27;precision&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;precision&#x27;: make_scorer(precision_score),\n",
       "                      &#x27;recall_score&#x27;: make_scorer(recall_score)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 1, 1: 1.0},\n",
       "                                          {0: 1, 1: 1.6551724137931034},\n",
       "                                          {0: 1, 1: 2.310344827586207},\n",
       "                                          {0: 1, 1: 2.9655172413793105},\n",
       "                                          {0: 1, 1: 3.6206896551724137},\n",
       "                                          {0: 1, 1: 4.275862068965517},\n",
       "                                          {0: 1, 1: 4.931034482758621},\n",
       "                                          {0: 1, 1: 5.586206896551724},\n",
       "                                          {0: 1, 1: 6.241379310344827},\n",
       "                                          {0: 1, 1: 6.896551724137931},...\n",
       "                                          {0: 1, 1: 14.758620689655173},\n",
       "                                          {0: 1, 1: 15.413793103448276},\n",
       "                                          {0: 1, 1: 16.06896551724138},\n",
       "                                          {0: 1, 1: 16.724137931034484},\n",
       "                                          {0: 1, 1: 17.379310344827587},\n",
       "                                          {0: 1, 1: 18.03448275862069},\n",
       "                                          {0: 1, 1: 18.689655172413794},\n",
       "                                          {0: 1, 1: 19.344827586206897},\n",
       "                                          {0: 1, 1: 20.0}]},\n",
       "             refit='precision', return_train_score=True,\n",
       "             scoring={'precision': make_scorer(precision_score),\n",
       "                      'recall_score': make_scorer(recall_score)})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator = LogisticRegression(max_iter=1000),\n",
    "    param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace (1, 20, 30)]},\n",
    "    scoring={'precision': make_scorer(precision_score), 'recall_score': make_scorer(recall_score)}, \n",
    "    refit = 'precision',\n",
    "    return_train_score=True,\n",
    "    cv = 10,\n",
    "    n_jobs = -1\n",
    ")\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444cdf4f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.25329273, 2.27790389, 2.23323812, 2.2865097 , 1.9832376 ,\n",
       "        2.22665834, 2.36122005, 2.27303507, 2.24202998, 2.48400667,\n",
       "        2.2269479 , 2.22037094, 2.10040367, 2.22826748, 2.11302211,\n",
       "        2.09930232, 2.14891469, 2.12790356, 2.25552044, 2.31666498,\n",
       "        2.17687933, 2.24095075, 2.10560982, 2.59087341, 2.6941654 ,\n",
       "        2.02329884, 2.23499794, 2.26342983, 2.10263088, 2.06769166]),\n",
       " 'std_fit_time': array([0.25929585, 0.35856549, 0.19149527, 0.23718132, 0.26369522,\n",
       "        0.29752443, 0.26942522, 0.31151026, 0.23015105, 0.50261382,\n",
       "        0.27150304, 0.24688955, 0.26183174, 0.39149623, 0.31174542,\n",
       "        0.33649426, 0.13332707, 0.20527122, 0.24954662, 0.24994735,\n",
       "        0.26600773, 0.23068892, 0.16477237, 0.63567697, 0.30741828,\n",
       "        0.27220509, 0.32796546, 0.29052956, 0.22049774, 0.22374875]),\n",
       " 'mean_score_time': array([0.02273827, 0.02473357, 0.0197484 , 0.01874771, 0.02683058,\n",
       "        0.02054586, 0.02978001, 0.02608986, 0.02623303, 0.02692811,\n",
       "        0.05261164, 0.0238328 , 0.01844866, 0.02802393, 0.03754551,\n",
       "        0.03550105, 0.02543366, 0.02763855, 0.03241341, 0.04922457,\n",
       "        0.02293925, 0.02623332, 0.02573271, 0.06941686, 0.03590548,\n",
       "        0.02992291, 0.02459941, 0.0300184 , 0.04222746, 0.02044525]),\n",
       " 'std_score_time': array([0.00838963, 0.00851911, 0.00647692, 0.00308398, 0.00814674,\n",
       "        0.00411525, 0.01185213, 0.0078811 , 0.01168059, 0.0121325 ,\n",
       "        0.03525957, 0.0108875 , 0.00343527, 0.01546057, 0.02747007,\n",
       "        0.02031486, 0.00839454, 0.0094824 , 0.01553425, 0.02876462,\n",
       "        0.00790328, 0.01138347, 0.00935303, 0.04221616, 0.02624192,\n",
       "        0.01192965, 0.0106916 , 0.01359665, 0.0255935 , 0.00698456]),\n",
       " 'param_class_weight': masked_array(data=[{0: 1, 1: 1.0}, {0: 1, 1: 1.6551724137931034},\n",
       "                    {0: 1, 1: 2.310344827586207},\n",
       "                    {0: 1, 1: 2.9655172413793105},\n",
       "                    {0: 1, 1: 3.6206896551724137},\n",
       "                    {0: 1, 1: 4.275862068965517},\n",
       "                    {0: 1, 1: 4.931034482758621},\n",
       "                    {0: 1, 1: 5.586206896551724},\n",
       "                    {0: 1, 1: 6.241379310344827},\n",
       "                    {0: 1, 1: 6.896551724137931},\n",
       "                    {0: 1, 1: 7.551724137931034},\n",
       "                    {0: 1, 1: 8.206896551724139},\n",
       "                    {0: 1, 1: 8.862068965517242},\n",
       "                    {0: 1, 1: 9.517241379310345},\n",
       "                    {0: 1, 1: 10.172413793103448},\n",
       "                    {0: 1, 1: 10.827586206896552},\n",
       "                    {0: 1, 1: 11.482758620689655},\n",
       "                    {0: 1, 1: 12.137931034482758},\n",
       "                    {0: 1, 1: 12.793103448275861},\n",
       "                    {0: 1, 1: 13.448275862068964},\n",
       "                    {0: 1, 1: 14.103448275862068},\n",
       "                    {0: 1, 1: 14.758620689655173},\n",
       "                    {0: 1, 1: 15.413793103448276},\n",
       "                    {0: 1, 1: 16.06896551724138},\n",
       "                    {0: 1, 1: 16.724137931034484},\n",
       "                    {0: 1, 1: 17.379310344827587},\n",
       "                    {0: 1, 1: 18.03448275862069},\n",
       "                    {0: 1, 1: 18.689655172413794},\n",
       "                    {0: 1, 1: 19.344827586206897}, {0: 1, 1: 20.0}],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'class_weight': {0: 1, 1: 1.0}},\n",
       "  {'class_weight': {0: 1, 1: 1.6551724137931034}},\n",
       "  {'class_weight': {0: 1, 1: 2.310344827586207}},\n",
       "  {'class_weight': {0: 1, 1: 2.9655172413793105}},\n",
       "  {'class_weight': {0: 1, 1: 3.6206896551724137}},\n",
       "  {'class_weight': {0: 1, 1: 4.275862068965517}},\n",
       "  {'class_weight': {0: 1, 1: 4.931034482758621}},\n",
       "  {'class_weight': {0: 1, 1: 5.586206896551724}},\n",
       "  {'class_weight': {0: 1, 1: 6.241379310344827}},\n",
       "  {'class_weight': {0: 1, 1: 6.896551724137931}},\n",
       "  {'class_weight': {0: 1, 1: 7.551724137931034}},\n",
       "  {'class_weight': {0: 1, 1: 8.206896551724139}},\n",
       "  {'class_weight': {0: 1, 1: 8.862068965517242}},\n",
       "  {'class_weight': {0: 1, 1: 9.517241379310345}},\n",
       "  {'class_weight': {0: 1, 1: 10.172413793103448}},\n",
       "  {'class_weight': {0: 1, 1: 10.827586206896552}},\n",
       "  {'class_weight': {0: 1, 1: 11.482758620689655}},\n",
       "  {'class_weight': {0: 1, 1: 12.137931034482758}},\n",
       "  {'class_weight': {0: 1, 1: 12.793103448275861}},\n",
       "  {'class_weight': {0: 1, 1: 13.448275862068964}},\n",
       "  {'class_weight': {0: 1, 1: 14.103448275862068}},\n",
       "  {'class_weight': {0: 1, 1: 14.758620689655173}},\n",
       "  {'class_weight': {0: 1, 1: 15.413793103448276}},\n",
       "  {'class_weight': {0: 1, 1: 16.06896551724138}},\n",
       "  {'class_weight': {0: 1, 1: 16.724137931034484}},\n",
       "  {'class_weight': {0: 1, 1: 17.379310344827587}},\n",
       "  {'class_weight': {0: 1, 1: 18.03448275862069}},\n",
       "  {'class_weight': {0: 1, 1: 18.689655172413794}},\n",
       "  {'class_weight': {0: 1, 1: 19.344827586206897}},\n",
       "  {'class_weight': {0: 1, 1: 20.0}}],\n",
       " 'split0_test_precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.89473684, 0.85      ,\n",
       "        0.85      , 0.85714286, 0.85714286, 0.85714286, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ]),\n",
       " 'split1_test_precision': array([0.46341463, 0.46341463, 0.46341463, 0.45238095, 0.45238095,\n",
       "        0.45238095, 0.45238095, 0.45238095, 0.45238095, 0.45238095,\n",
       "        0.45238095, 0.45238095, 0.44186047, 0.43181818, 0.43181818,\n",
       "        0.43181818, 0.43181818, 0.43181818, 0.41304348, 0.41304348,\n",
       "        0.41304348, 0.40425532, 0.3877551 , 0.38      , 0.38      ,\n",
       "        0.38      , 0.36538462, 0.34545455, 0.34545455, 0.33928571]),\n",
       " 'split2_test_precision': array([0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "        0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "        0.58333333, 0.58333333, 0.58333333, 0.56      , 0.56      ,\n",
       "        0.56      , 0.56      , 0.57692308, 0.57692308, 0.57692308,\n",
       "        0.57692308, 0.57692308, 0.57692308, 0.57692308, 0.55555556,\n",
       "        0.55555556, 0.53571429, 0.53571429, 0.53571429, 0.53571429]),\n",
       " 'split3_test_precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842]),\n",
       " 'split4_test_precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.92307692,\n",
       "        0.92307692, 0.92307692, 0.86666667, 0.86666667, 0.86666667]),\n",
       " 'split5_test_precision': array([0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.89473684, 0.89473684, 0.85      ,\n",
       "        0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "        0.85      , 0.85      , 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182]),\n",
       " 'split6_test_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split7_test_precision': array([0.81818182, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
       "        0.83333333, 0.84615385, 0.85714286, 0.875     , 0.875     ,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
       "        0.875     , 0.88235294, 0.88235294, 0.88235294, 0.88235294,\n",
       "        0.88235294, 0.88235294, 0.88235294, 0.88235294, 0.83333333,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.75      , 0.71428571]),\n",
       " 'split8_test_precision': array([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split9_test_precision': array([1.        , 1.        , 1.        , 1.        , 0.92857143,\n",
       "        0.93333333, 0.94117647, 0.94117647, 0.94117647, 0.94117647,\n",
       "        0.94117647, 0.94117647, 0.94117647, 0.94117647, 0.94117647,\n",
       "        0.94117647, 0.94117647, 0.94117647, 0.88888889, 0.88888889,\n",
       "        0.88888889, 0.84210526, 0.84210526, 0.84210526, 0.8       ,\n",
       "        0.8       , 0.8       , 0.8       , 0.8       , 0.8       ]),\n",
       " 'mean_test_precision': array([0.78093742, 0.88245257, 0.88245257, 0.88134921, 0.87420635,\n",
       "        0.87468254, 0.8767489 , 0.87287705, 0.86384405, 0.85937036,\n",
       "        0.85937036, 0.85937036, 0.85831831, 0.85000999, 0.84553631,\n",
       "        0.84553631, 0.84698589, 0.84939248, 0.84228625, 0.83839015,\n",
       "        0.83839015, 0.83283297, 0.83118295, 0.82295402, 0.80401247,\n",
       "        0.79962651, 0.79618084, 0.78854681, 0.78459944, 0.78041113]),\n",
       " 'std_test_precision': array([0.31902901, 0.18820871, 0.18820871, 0.19067822, 0.18740959,\n",
       "        0.18755312, 0.18756457, 0.18623748, 0.18003759, 0.17976999,\n",
       "        0.17976999, 0.17976999, 0.18216354, 0.18625149, 0.18565978,\n",
       "        0.18565978, 0.18581622, 0.18327189, 0.18562023, 0.18567639,\n",
       "        0.18567639, 0.18693992, 0.19074947, 0.19282111, 0.18830869,\n",
       "        0.18808533, 0.19395897, 0.19546163, 0.19580135, 0.19809322]),\n",
       " 'rank_test_precision': array([29,  1,  1,  3,  6,  5,  4,  7,  8,  9,  9,  9, 12, 13, 16, 16, 15,\n",
       "        14, 18, 19, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30]),\n",
       " 'split0_train_precision': array([0.80434783, 0.76821192, 0.77848101, 0.77639752, 0.79041916,\n",
       "        0.79411765, 0.80225989, 0.80446927, 0.81111111, 0.80978261,\n",
       "        0.80978261, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
       "        0.80645161, 0.80748663, 0.80319149, 0.80319149, 0.80319149,\n",
       "        0.80319149, 0.79581152, 0.79581152, 0.79166667, 0.79166667,\n",
       "        0.79166667, 0.79166667, 0.79166667, 0.78350515, 0.78571429]),\n",
       " 'split1_train_precision': array([0.91724138, 0.92307692, 0.91975309, 0.91975309, 0.92073171,\n",
       "        0.92073171, 0.92073171, 0.91071429, 0.90532544, 0.89473684,\n",
       "        0.89473684, 0.88953488, 0.88953488, 0.87931034, 0.87931034,\n",
       "        0.87931034, 0.87428571, 0.875     , 0.8700565 , 0.86516854,\n",
       "        0.8603352 , 0.85555556, 0.84615385, 0.84615385, 0.82795699,\n",
       "        0.82795699, 0.81914894, 0.81052632, 0.79381443, 0.78571429]),\n",
       " 'split2_train_precision': array([0.84090909, 0.82876712, 0.83974359, 0.84756098, 0.84883721,\n",
       "        0.84659091, 0.84745763, 0.84745763, 0.83798883, 0.83888889,\n",
       "        0.83977901, 0.83977901, 0.84153005, 0.83695652, 0.83243243,\n",
       "        0.83243243, 0.82795699, 0.82887701, 0.82539683, 0.82539683,\n",
       "        0.81675393, 0.80829016, 0.80412371, 0.79187817, 0.7839196 ,\n",
       "        0.77227723, 0.76470588, 0.76097561, 0.75728155, 0.75728155]),\n",
       " 'split3_train_precision': array([0.7578125 , 0.76551724, 0.77564103, 0.78125   , 0.78915663,\n",
       "        0.79532164, 0.80225989, 0.80446927, 0.80662983, 0.80769231,\n",
       "        0.80978261, 0.80978261, 0.80978261, 0.80540541, 0.80107527,\n",
       "        0.79679144, 0.79679144, 0.79473684, 0.79473684, 0.79581152,\n",
       "        0.79581152, 0.79166667, 0.78756477, 0.78756477, 0.78756477,\n",
       "        0.78461538, 0.77272727, 0.77272727, 0.76884422, 0.76884422]),\n",
       " 'split4_train_precision': array([0.7593985 , 0.77631579, 0.78616352, 0.79393939, 0.79166667,\n",
       "        0.79651163, 0.79885057, 0.8021978 , 0.80540541, 0.80540541,\n",
       "        0.80645161, 0.80748663, 0.80748663, 0.80748663, 0.80748663,\n",
       "        0.80319149, 0.8042328 , 0.80104712, 0.80104712, 0.80104712,\n",
       "        0.79792746, 0.79792746, 0.79792746, 0.78974359, 0.78974359,\n",
       "        0.78974359, 0.77777778, 0.76237624, 0.75490196, 0.75121951]),\n",
       " 'split5_train_precision': array([0.74814815, 0.77027027, 0.78343949, 0.79141104, 0.79393939,\n",
       "        0.80346821, 0.81355932, 0.81111111, 0.8121547 , 0.8121547 ,\n",
       "        0.81318681, 0.81420765, 0.81420765, 0.80978261, 0.81081081,\n",
       "        0.80645161, 0.80213904, 0.80213904, 0.80213904, 0.7989418 ,\n",
       "        0.7989418 , 0.79473684, 0.79166667, 0.79166667, 0.79166667,\n",
       "        0.79166667, 0.79166667, 0.79381443, 0.79381443, 0.78974359]),\n",
       " 'split6_train_precision': array([0.73880597, 0.76027397, 0.77564103, 0.7826087 , 0.78527607,\n",
       "        0.79532164, 0.80113636, 0.79888268, 0.80110497, 0.8021978 ,\n",
       "        0.80327869, 0.80327869, 0.79459459, 0.79459459, 0.79459459,\n",
       "        0.79459459, 0.79144385, 0.78723404, 0.78835979, 0.78947368,\n",
       "        0.78534031, 0.78125   , 0.78125   , 0.78125   , 0.77319588,\n",
       "        0.76923077, 0.76530612, 0.76262626, 0.74752475, 0.74384236]),\n",
       " 'split7_train_precision': array([0.76595745, 0.78571429, 0.79245283, 0.80120482, 0.80588235,\n",
       "        0.80813953, 0.81034483, 0.81142857, 0.81111111, 0.8121547 ,\n",
       "        0.8121547 , 0.80540541, 0.80645161, 0.8       , 0.79581152,\n",
       "        0.79581152, 0.79581152, 0.796875  , 0.79274611, 0.78865979,\n",
       "        0.78865979, 0.78461538, 0.78461538, 0.78461538, 0.78461538,\n",
       "        0.78061224, 0.77664975, 0.77272727, 0.75742574, 0.75742574]),\n",
       " 'split8_train_precision': array([0.76190476, 0.77848101, 0.78915663, 0.79532164, 0.79768786,\n",
       "        0.8       , 0.80446927, 0.80769231, 0.80748663, 0.80851064,\n",
       "        0.8042328 , 0.80104712, 0.80104712, 0.80104712, 0.796875  ,\n",
       "        0.79792746, 0.79896907, 0.79487179, 0.79591837, 0.78787879,\n",
       "        0.78787879, 0.78787879, 0.7839196 , 0.7839196 , 0.7839196 ,\n",
       "        0.7839196 , 0.785     , 0.78217822, 0.78217822, 0.78217822]),\n",
       " 'split9_train_precision': array([0.75352113, 0.77564103, 0.78527607, 0.78787879, 0.79289941,\n",
       "        0.79532164, 0.79885057, 0.80446927, 0.80662983, 0.80978261,\n",
       "        0.80978261, 0.80213904, 0.80319149, 0.80319149, 0.80319149,\n",
       "        0.7989418 , 0.79581152, 0.79581152, 0.79581152, 0.79581152,\n",
       "        0.79581152, 0.79581152, 0.79581152, 0.796875  , 0.79274611,\n",
       "        0.78974359, 0.78571429, 0.78172589, 0.78172589, 0.78172589]),\n",
       " 'mean_train_precision': array([0.78480467, 0.79322696, 0.80257483, 0.8077326 , 0.81164965,\n",
       "        0.81555245, 0.819992  , 0.82028922, 0.82049479, 0.82013065,\n",
       "        0.82031683, 0.81791126, 0.81742783, 0.81442263, 0.81280397,\n",
       "        0.81119043, 0.80949286, 0.80797839, 0.80694036, 0.80513811,\n",
       "        0.80306518, 0.79935439, 0.79688445, 0.79453337, 0.79069953,\n",
       "        0.78814327, 0.78303634, 0.77913442, 0.77210164, 0.77036897]),\n",
       " 'std_train_precision': array([0.05268875, 0.04690388, 0.04284959, 0.04182915, 0.04028248,\n",
       "        0.03810352, 0.03627198, 0.03282163, 0.02984173, 0.02662237,\n",
       "        0.02666218, 0.02613733, 0.02679795, 0.02416378, 0.02446424,\n",
       "        0.02499128, 0.023658  , 0.02466267, 0.02310217, 0.02249834,\n",
       "        0.02090023, 0.02005662, 0.01777753, 0.0177556 , 0.01356557,\n",
       "        0.01520361, 0.01513009, 0.01529442, 0.01616346, 0.01589423]),\n",
       " 'split0_test_recall_score': array([0.36842105, 0.42105263, 0.42105263, 0.63157895, 0.78947368,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842]),\n",
       " 'split1_test_recall_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_recall_score': array([0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
       "        0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
       "        0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
       "        0.73684211, 0.73684211, 0.78947368, 0.78947368, 0.78947368,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368]),\n",
       " 'split3_test_recall_score': array([0.47368421, 0.78947368, 0.84210526, 0.84210526, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842]),\n",
       " 'split4_test_recall_score': array([0.35, 0.35, 0.4 , 0.4 , 0.45, 0.45, 0.45, 0.45, 0.5 , 0.5 , 0.5 ,\n",
       "        0.5 , 0.5 , 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.6 , 0.6 , 0.6 ,\n",
       "        0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.65, 0.65, 0.65]),\n",
       " 'split5_test_recall_score': array([0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85,\n",
       "        0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.9 , 0.9 , 0.9 , 0.9 , 0.9 ,\n",
       "        0.9 , 0.9 , 0.9 , 0.9 , 0.9 , 0.9 , 0.9 , 0.9 ]),\n",
       " 'split6_test_recall_score': array([0.9 , 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 1.  , 1.  , 1.  , 1.  ,\n",
       "        1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "        1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ]),\n",
       " 'split7_test_recall_score': array([0.45, 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.55, 0.6 , 0.7 , 0.7 , 0.7 ,\n",
       "        0.7 , 0.7 , 0.7 , 0.7 , 0.7 , 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "        0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]),\n",
       " 'split8_test_recall_score': array([0.  , 0.25, 0.25, 0.25, 0.3 , 0.35, 0.35, 0.35, 0.4 , 0.5 , 0.5 ,\n",
       "        0.55, 0.6 , 0.6 , 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65,\n",
       "        0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65]),\n",
       " 'split9_test_recall_score': array([0.4 , 0.5 , 0.55, 0.65, 0.65, 0.7 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ,\n",
       "        0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ,\n",
       "        0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ]),\n",
       " 'mean_test_recall_score': array([0.55289474, 0.63473684, 0.65      , 0.68105263, 0.71210526,\n",
       "        0.73263158, 0.74763158, 0.76289474, 0.78289474, 0.79289474,\n",
       "        0.79289474, 0.79789474, 0.80289474, 0.80789474, 0.81289474,\n",
       "        0.81289474, 0.82315789, 0.83342105, 0.83342105, 0.83842105,\n",
       "        0.83842105, 0.83842105, 0.83842105, 0.83842105, 0.83842105,\n",
       "        0.83842105, 0.83842105, 0.84342105, 0.84342105, 0.84342105]),\n",
       " 'std_test_recall_score': array([0.29387433, 0.24991633, 0.24583793, 0.23079052, 0.22041324,\n",
       "        0.21599861, 0.21142718, 0.21642861, 0.19345685, 0.17512184,\n",
       "        0.17512184, 0.16722354, 0.16034265, 0.15134668, 0.14509262,\n",
       "        0.14509262, 0.14562312, 0.14487099, 0.14487099, 0.13556693,\n",
       "        0.13556693, 0.13556693, 0.13556693, 0.13556693, 0.13556693,\n",
       "        0.13556693, 0.13556693, 0.12735456, 0.12735456, 0.12735456]),\n",
       " 'rank_test_recall_score': array([30, 29, 28, 27, 26, 25, 24, 23, 22, 20, 20, 19, 18, 17, 15, 15, 14,\n",
       "        12, 12,  4,  4,  4,  4,  4,  4,  4,  4,  1,  1,  1]),\n",
       " 'split0_train_recall_score': array([0.62711864, 0.65536723, 0.69491525, 0.70621469, 0.74576271,\n",
       "        0.76271186, 0.80225989, 0.81355932, 0.82485876, 0.84180791,\n",
       "        0.84180791, 0.84745763, 0.84745763, 0.84745763, 0.84745763,\n",
       "        0.84745763, 0.85310734, 0.85310734, 0.85310734, 0.85310734,\n",
       "        0.85310734, 0.85875706, 0.85875706, 0.85875706, 0.85875706,\n",
       "        0.85875706, 0.85875706, 0.85875706, 0.85875706, 0.8700565 ]),\n",
       " 'split1_train_recall_score': array([0.75141243, 0.81355932, 0.84180791, 0.84180791, 0.85310734,\n",
       "        0.85310734, 0.85310734, 0.86440678, 0.86440678, 0.86440678,\n",
       "        0.86440678, 0.86440678, 0.86440678, 0.86440678, 0.86440678,\n",
       "        0.86440678, 0.86440678, 0.8700565 , 0.8700565 , 0.8700565 ,\n",
       "        0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 ,\n",
       "        0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 ]),\n",
       " 'split2_train_recall_score': array([0.62711864, 0.68361582, 0.74011299, 0.78531073, 0.82485876,\n",
       "        0.84180791, 0.84745763, 0.84745763, 0.84745763, 0.85310734,\n",
       "        0.85875706, 0.85875706, 0.8700565 , 0.8700565 , 0.8700565 ,\n",
       "        0.8700565 , 0.8700565 , 0.87570621, 0.88135593, 0.88135593,\n",
       "        0.88135593, 0.88135593, 0.88135593, 0.88135593, 0.88135593,\n",
       "        0.88135593, 0.88135593, 0.88135593, 0.88135593, 0.88135593]),\n",
       " 'split3_train_recall_score': array([0.5480226 , 0.62711864, 0.68361582, 0.70621469, 0.74011299,\n",
       "        0.76836158, 0.80225989, 0.81355932, 0.82485876, 0.83050847,\n",
       "        0.84180791, 0.84180791, 0.84180791, 0.84180791, 0.84180791,\n",
       "        0.84180791, 0.84180791, 0.85310734, 0.85310734, 0.85875706,\n",
       "        0.85875706, 0.85875706, 0.85875706, 0.85875706, 0.85875706,\n",
       "        0.86440678, 0.86440678, 0.86440678, 0.86440678, 0.86440678]),\n",
       " 'split4_train_recall_score': array([0.57386364, 0.67045455, 0.71022727, 0.74431818, 0.75568182,\n",
       "        0.77840909, 0.78977273, 0.82954545, 0.84659091, 0.84659091,\n",
       "        0.85227273, 0.85795455, 0.85795455, 0.85795455, 0.85795455,\n",
       "        0.85795455, 0.86363636, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ]),\n",
       " 'split5_train_recall_score': array([0.57386364, 0.64772727, 0.69886364, 0.73295455, 0.74431818,\n",
       "        0.78977273, 0.81818182, 0.82954545, 0.83522727, 0.83522727,\n",
       "        0.84090909, 0.84659091, 0.84659091, 0.84659091, 0.85227273,\n",
       "        0.85227273, 0.85227273, 0.85227273, 0.85227273, 0.85795455,\n",
       "        0.85795455, 0.85795455, 0.86363636, 0.86363636, 0.86363636,\n",
       "        0.86363636, 0.86363636, 0.875     , 0.875     , 0.875     ]),\n",
       " 'split6_train_recall_score': array([0.5625    , 0.63068182, 0.6875    , 0.71590909, 0.72727273,\n",
       "        0.77272727, 0.80113636, 0.8125    , 0.82386364, 0.82954545,\n",
       "        0.83522727, 0.83522727, 0.83522727, 0.83522727, 0.83522727,\n",
       "        0.83522727, 0.84090909, 0.84090909, 0.84659091, 0.85227273,\n",
       "        0.85227273, 0.85227273, 0.85227273, 0.85227273, 0.85227273,\n",
       "        0.85227273, 0.85227273, 0.85795455, 0.85795455, 0.85795455]),\n",
       " 'split7_train_recall_score': array([0.61363636, 0.6875    , 0.71590909, 0.75568182, 0.77840909,\n",
       "        0.78977273, 0.80113636, 0.80681818, 0.82954545, 0.83522727,\n",
       "        0.83522727, 0.84659091, 0.85227273, 0.86363636, 0.86363636,\n",
       "        0.86363636, 0.86363636, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.86931818, 0.86931818, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.86931818, 0.86931818, 0.86931818, 0.86931818, 0.86931818]),\n",
       " 'split8_train_recall_score': array([0.63636364, 0.69886364, 0.74431818, 0.77272727, 0.78409091,\n",
       "        0.79545455, 0.81818182, 0.83522727, 0.85795455, 0.86363636,\n",
       "        0.86363636, 0.86931818, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.875     , 0.88068182, 0.88068182, 0.88636364, 0.88636364,\n",
       "        0.88636364, 0.88636364, 0.88636364, 0.88636364, 0.88636364,\n",
       "        0.88636364, 0.89204545, 0.89772727, 0.89772727, 0.89772727]),\n",
       " 'split9_train_recall_score': array([0.60795455, 0.6875    , 0.72727273, 0.73863636, 0.76136364,\n",
       "        0.77272727, 0.78977273, 0.81818182, 0.82954545, 0.84659091,\n",
       "        0.84659091, 0.85227273, 0.85795455, 0.85795455, 0.85795455,\n",
       "        0.85795455, 0.86363636, 0.86363636, 0.86363636, 0.86363636,\n",
       "        0.86363636, 0.86363636, 0.86363636, 0.86931818, 0.86931818,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ]),\n",
       " 'mean_train_recall_score': array([0.61218541, 0.68023883, 0.72445429, 0.74997753, 0.77149782,\n",
       "        0.79248523, 0.81232666, 0.82708012, 0.83843092, 0.84466487,\n",
       "        0.84806433, 0.85203839, 0.8543047 , 0.85544106, 0.85600924,\n",
       "        0.85657743, 0.85941513, 0.86281138, 0.86451271, 0.86621405,\n",
       "        0.86678223, 0.8673472 , 0.86791538, 0.86848356, 0.86848356,\n",
       "        0.86961672, 0.8701849 , 0.87245763, 0.87245763, 0.87358757]),\n",
       " 'std_train_recall_score': array([0.05473334, 0.05028625, 0.04388149, 0.0395889 , 0.03795866,\n",
       "        0.02928924, 0.02106253, 0.01719007, 0.01397413, 0.01201522,\n",
       "        0.01050163, 0.00999687, 0.01110338, 0.01141441, 0.01109672,\n",
       "        0.01188135, 0.01177783, 0.01184309, 0.01253003, 0.01079785,\n",
       "        0.01109173, 0.01050939, 0.01013308, 0.01003605, 0.01003605,\n",
       "        0.00978859, 0.01085138, 0.01102546, 0.01102546, 0.01010396])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27008196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878787878787878"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y, grid.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16856142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_recall_score</th>\n",
       "      <th>split3_train_recall_score</th>\n",
       "      <th>split4_train_recall_score</th>\n",
       "      <th>split5_train_recall_score</th>\n",
       "      <th>split6_train_recall_score</th>\n",
       "      <th>split7_train_recall_score</th>\n",
       "      <th>split8_train_recall_score</th>\n",
       "      <th>split9_train_recall_score</th>\n",
       "      <th>mean_train_recall_score</th>\n",
       "      <th>std_train_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.253293</td>\n",
       "      <td>0.259296</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>{0: 1, 1: 1.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.0}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.548023</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.612185</td>\n",
       "      <td>0.054733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.277904</td>\n",
       "      <td>0.358565</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.008519</td>\n",
       "      <td>{0: 1, 1: 1.6551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.6551724137931034}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.630682</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.680239</td>\n",
       "      <td>0.050286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.233238</td>\n",
       "      <td>0.191495</td>\n",
       "      <td>0.019748</td>\n",
       "      <td>0.006477</td>\n",
       "      <td>{0: 1, 1: 2.310344827586207}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.310344827586207}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.724454</td>\n",
       "      <td>0.043881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.286510</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.018748</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>{0: 1, 1: 2.9655172413793105}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.9655172413793105}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.732955</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.749978</td>\n",
       "      <td>0.039589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.983238</td>\n",
       "      <td>0.263695</td>\n",
       "      <td>0.026831</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>{0: 1, 1: 3.6206896551724137}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3.6206896551724137}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.771498</td>\n",
       "      <td>0.037959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.226658</td>\n",
       "      <td>0.297524</td>\n",
       "      <td>0.020546</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>{0: 1, 1: 4.275862068965517}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.275862068965517}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.768362</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.792485</td>\n",
       "      <td>0.029289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.361220</td>\n",
       "      <td>0.269425</td>\n",
       "      <td>0.029780</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>{0: 1, 1: 4.931034482758621}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.931034482758621}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.812327</td>\n",
       "      <td>0.021063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.273035</td>\n",
       "      <td>0.311510</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>{0: 1, 1: 5.586206896551724}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 5.586206896551724}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.827080</td>\n",
       "      <td>0.017190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.242030</td>\n",
       "      <td>0.230151</td>\n",
       "      <td>0.026233</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>{0: 1, 1: 6.241379310344827}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.241379310344827}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.823864</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.838431</td>\n",
       "      <td>0.013974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.484007</td>\n",
       "      <td>0.502614</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>{0: 1, 1: 6.896551724137931}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.896551724137931}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.844665</td>\n",
       "      <td>0.012015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.226948</td>\n",
       "      <td>0.271503</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>0.035260</td>\n",
       "      <td>{0: 1, 1: 7.551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 7.551724137931034}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.848064</td>\n",
       "      <td>0.010502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.220371</td>\n",
       "      <td>0.246890</td>\n",
       "      <td>0.023833</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>{0: 1, 1: 8.206896551724139}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.206896551724139}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.852038</td>\n",
       "      <td>0.009997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.100404</td>\n",
       "      <td>0.261832</td>\n",
       "      <td>0.018449</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>{0: 1, 1: 8.862068965517242}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.862068965517242}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.011103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.228267</td>\n",
       "      <td>0.391496</td>\n",
       "      <td>0.028024</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>{0: 1, 1: 9.517241379310345}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 9.517241379310345}}</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.855441</td>\n",
       "      <td>0.011414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.113022</td>\n",
       "      <td>0.311745</td>\n",
       "      <td>0.037546</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>{0: 1, 1: 10.172413793103448}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.172413793103448}}</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.856009</td>\n",
       "      <td>0.011097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.099302</td>\n",
       "      <td>0.336494</td>\n",
       "      <td>0.035501</td>\n",
       "      <td>0.020315</td>\n",
       "      <td>{0: 1, 1: 10.827586206896552}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.827586206896552}}</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.856577</td>\n",
       "      <td>0.011881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.148915</td>\n",
       "      <td>0.133327</td>\n",
       "      <td>0.025434</td>\n",
       "      <td>0.008395</td>\n",
       "      <td>{0: 1, 1: 11.482758620689655}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 11.482758620689655}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.859415</td>\n",
       "      <td>0.011778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.127904</td>\n",
       "      <td>0.205271</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.009482</td>\n",
       "      <td>{0: 1, 1: 12.137931034482758}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.137931034482758}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.862811</td>\n",
       "      <td>0.011843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.255520</td>\n",
       "      <td>0.249547</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>0.015534</td>\n",
       "      <td>{0: 1, 1: 12.793103448275861}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.793103448275861}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.864513</td>\n",
       "      <td>0.012530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.316665</td>\n",
       "      <td>0.249947</td>\n",
       "      <td>0.049225</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>{0: 1, 1: 13.448275862068964}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 13.448275862068964}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.866214</td>\n",
       "      <td>0.010798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.176879</td>\n",
       "      <td>0.266008</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>{0: 1, 1: 14.103448275862068}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.103448275862068}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.866782</td>\n",
       "      <td>0.011092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.240951</td>\n",
       "      <td>0.230689</td>\n",
       "      <td>0.026233</td>\n",
       "      <td>0.011383</td>\n",
       "      <td>{0: 1, 1: 14.758620689655173}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.758620689655173}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.010509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.105610</td>\n",
       "      <td>0.164772</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>0.009353</td>\n",
       "      <td>{0: 1, 1: 15.413793103448276}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 15.413793103448276}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.867915</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.590873</td>\n",
       "      <td>0.635677</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.042216</td>\n",
       "      <td>{0: 1, 1: 16.06896551724138}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.06896551724138}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.010036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.694165</td>\n",
       "      <td>0.307418</td>\n",
       "      <td>0.035905</td>\n",
       "      <td>0.026242</td>\n",
       "      <td>{0: 1, 1: 16.724137931034484}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.724137931034484}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.010036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.023299</td>\n",
       "      <td>0.272205</td>\n",
       "      <td>0.029923</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>{0: 1, 1: 17.379310344827587}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 17.379310344827587}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869617</td>\n",
       "      <td>0.009789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.234998</td>\n",
       "      <td>0.327965</td>\n",
       "      <td>0.024599</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>{0: 1, 1: 18.03448275862069}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.03448275862069}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.870185</td>\n",
       "      <td>0.010851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.263430</td>\n",
       "      <td>0.290530</td>\n",
       "      <td>0.030018</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>{0: 1, 1: 18.689655172413794}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.689655172413794}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.872458</td>\n",
       "      <td>0.011025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.102631</td>\n",
       "      <td>0.220498</td>\n",
       "      <td>0.042227</td>\n",
       "      <td>0.025593</td>\n",
       "      <td>{0: 1, 1: 19.344827586206897}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 19.344827586206897}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.872458</td>\n",
       "      <td>0.011025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.067692</td>\n",
       "      <td>0.223749</td>\n",
       "      <td>0.020445</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>{0: 1, 1: 20.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 20.0}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873588</td>\n",
       "      <td>0.010104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.253293      0.259296         0.022738        0.008390   \n",
       "1        2.277904      0.358565         0.024734        0.008519   \n",
       "2        2.233238      0.191495         0.019748        0.006477   \n",
       "3        2.286510      0.237181         0.018748        0.003084   \n",
       "4        1.983238      0.263695         0.026831        0.008147   \n",
       "5        2.226658      0.297524         0.020546        0.004115   \n",
       "6        2.361220      0.269425         0.029780        0.011852   \n",
       "7        2.273035      0.311510         0.026090        0.007881   \n",
       "8        2.242030      0.230151         0.026233        0.011681   \n",
       "9        2.484007      0.502614         0.026928        0.012133   \n",
       "10       2.226948      0.271503         0.052612        0.035260   \n",
       "11       2.220371      0.246890         0.023833        0.010887   \n",
       "12       2.100404      0.261832         0.018449        0.003435   \n",
       "13       2.228267      0.391496         0.028024        0.015461   \n",
       "14       2.113022      0.311745         0.037546        0.027470   \n",
       "15       2.099302      0.336494         0.035501        0.020315   \n",
       "16       2.148915      0.133327         0.025434        0.008395   \n",
       "17       2.127904      0.205271         0.027639        0.009482   \n",
       "18       2.255520      0.249547         0.032413        0.015534   \n",
       "19       2.316665      0.249947         0.049225        0.028765   \n",
       "20       2.176879      0.266008         0.022939        0.007903   \n",
       "21       2.240951      0.230689         0.026233        0.011383   \n",
       "22       2.105610      0.164772         0.025733        0.009353   \n",
       "23       2.590873      0.635677         0.069417        0.042216   \n",
       "24       2.694165      0.307418         0.035905        0.026242   \n",
       "25       2.023299      0.272205         0.029923        0.011930   \n",
       "26       2.234998      0.327965         0.024599        0.010692   \n",
       "27       2.263430      0.290530         0.030018        0.013597   \n",
       "28       2.102631      0.220498         0.042227        0.025593   \n",
       "29       2.067692      0.223749         0.020445        0.006985   \n",
       "\n",
       "               param_class_weight  \\\n",
       "0                  {0: 1, 1: 1.0}   \n",
       "1   {0: 1, 1: 1.6551724137931034}   \n",
       "2    {0: 1, 1: 2.310344827586207}   \n",
       "3   {0: 1, 1: 2.9655172413793105}   \n",
       "4   {0: 1, 1: 3.6206896551724137}   \n",
       "5    {0: 1, 1: 4.275862068965517}   \n",
       "6    {0: 1, 1: 4.931034482758621}   \n",
       "7    {0: 1, 1: 5.586206896551724}   \n",
       "8    {0: 1, 1: 6.241379310344827}   \n",
       "9    {0: 1, 1: 6.896551724137931}   \n",
       "10   {0: 1, 1: 7.551724137931034}   \n",
       "11   {0: 1, 1: 8.206896551724139}   \n",
       "12   {0: 1, 1: 8.862068965517242}   \n",
       "13   {0: 1, 1: 9.517241379310345}   \n",
       "14  {0: 1, 1: 10.172413793103448}   \n",
       "15  {0: 1, 1: 10.827586206896552}   \n",
       "16  {0: 1, 1: 11.482758620689655}   \n",
       "17  {0: 1, 1: 12.137931034482758}   \n",
       "18  {0: 1, 1: 12.793103448275861}   \n",
       "19  {0: 1, 1: 13.448275862068964}   \n",
       "20  {0: 1, 1: 14.103448275862068}   \n",
       "21  {0: 1, 1: 14.758620689655173}   \n",
       "22  {0: 1, 1: 15.413793103448276}   \n",
       "23   {0: 1, 1: 16.06896551724138}   \n",
       "24  {0: 1, 1: 16.724137931034484}   \n",
       "25  {0: 1, 1: 17.379310344827587}   \n",
       "26   {0: 1, 1: 18.03448275862069}   \n",
       "27  {0: 1, 1: 18.689655172413794}   \n",
       "28  {0: 1, 1: 19.344827586206897}   \n",
       "29                {0: 1, 1: 20.0}   \n",
       "\n",
       "                                             params  split0_test_precision  \\\n",
       "0                  {'class_weight': {0: 1, 1: 1.0}}               1.000000   \n",
       "1   {'class_weight': {0: 1, 1: 1.6551724137931034}}               1.000000   \n",
       "2    {'class_weight': {0: 1, 1: 2.310344827586207}}               1.000000   \n",
       "3   {'class_weight': {0: 1, 1: 2.9655172413793105}}               1.000000   \n",
       "4   {'class_weight': {0: 1, 1: 3.6206896551724137}}               1.000000   \n",
       "5    {'class_weight': {0: 1, 1: 4.275862068965517}}               1.000000   \n",
       "6    {'class_weight': {0: 1, 1: 4.931034482758621}}               1.000000   \n",
       "7    {'class_weight': {0: 1, 1: 5.586206896551724}}               1.000000   \n",
       "8    {'class_weight': {0: 1, 1: 6.241379310344827}}               0.944444   \n",
       "9    {'class_weight': {0: 1, 1: 6.896551724137931}}               0.944444   \n",
       "10   {'class_weight': {0: 1, 1: 7.551724137931034}}               0.944444   \n",
       "11   {'class_weight': {0: 1, 1: 8.206896551724139}}               0.944444   \n",
       "12   {'class_weight': {0: 1, 1: 8.862068965517242}}               0.944444   \n",
       "13   {'class_weight': {0: 1, 1: 9.517241379310345}}               0.894737   \n",
       "14  {'class_weight': {0: 1, 1: 10.172413793103448}}               0.850000   \n",
       "15  {'class_weight': {0: 1, 1: 10.827586206896552}}               0.850000   \n",
       "16  {'class_weight': {0: 1, 1: 11.482758620689655}}               0.857143   \n",
       "17  {'class_weight': {0: 1, 1: 12.137931034482758}}               0.857143   \n",
       "18  {'class_weight': {0: 1, 1: 12.793103448275861}}               0.857143   \n",
       "19  {'class_weight': {0: 1, 1: 13.448275862068964}}               0.818182   \n",
       "20  {'class_weight': {0: 1, 1: 14.103448275862068}}               0.818182   \n",
       "21  {'class_weight': {0: 1, 1: 14.758620689655173}}               0.818182   \n",
       "22  {'class_weight': {0: 1, 1: 15.413793103448276}}               0.818182   \n",
       "23   {'class_weight': {0: 1, 1: 16.06896551724138}}               0.782609   \n",
       "24  {'class_weight': {0: 1, 1: 16.724137931034484}}               0.782609   \n",
       "25  {'class_weight': {0: 1, 1: 17.379310344827587}}               0.782609   \n",
       "26   {'class_weight': {0: 1, 1: 18.03448275862069}}               0.782609   \n",
       "27  {'class_weight': {0: 1, 1: 18.689655172413794}}               0.782609   \n",
       "28  {'class_weight': {0: 1, 1: 19.344827586206897}}               0.782609   \n",
       "29                {'class_weight': {0: 1, 1: 20.0}}               0.782609   \n",
       "\n",
       "    split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n",
       "0                0.463415               0.583333               1.000000  ...   \n",
       "1                0.463415               0.583333               1.000000  ...   \n",
       "2                0.463415               0.583333               1.000000  ...   \n",
       "3                0.452381               0.583333               1.000000  ...   \n",
       "4                0.452381               0.583333               1.000000  ...   \n",
       "5                0.452381               0.583333               1.000000  ...   \n",
       "6                0.452381               0.583333               1.000000  ...   \n",
       "7                0.452381               0.583333               1.000000  ...   \n",
       "8                0.452381               0.583333               0.947368  ...   \n",
       "9                0.452381               0.583333               0.947368  ...   \n",
       "10               0.452381               0.583333               0.947368  ...   \n",
       "11               0.452381               0.583333               0.947368  ...   \n",
       "12               0.441860               0.583333               0.947368  ...   \n",
       "13               0.431818               0.560000               0.947368  ...   \n",
       "14               0.431818               0.560000               0.947368  ...   \n",
       "15               0.431818               0.560000               0.947368  ...   \n",
       "16               0.431818               0.560000               0.947368  ...   \n",
       "17               0.431818               0.576923               0.947368  ...   \n",
       "18               0.413043               0.576923               0.947368  ...   \n",
       "19               0.413043               0.576923               0.947368  ...   \n",
       "20               0.413043               0.576923               0.947368  ...   \n",
       "21               0.404255               0.576923               0.947368  ...   \n",
       "22               0.387755               0.576923               0.947368  ...   \n",
       "23               0.380000               0.576923               0.947368  ...   \n",
       "24               0.380000               0.555556               0.947368  ...   \n",
       "25               0.380000               0.555556               0.947368  ...   \n",
       "26               0.365385               0.535714               0.947368  ...   \n",
       "27               0.345455               0.535714               0.947368  ...   \n",
       "28               0.345455               0.535714               0.947368  ...   \n",
       "29               0.339286               0.535714               0.947368  ...   \n",
       "\n",
       "    split2_train_recall_score  split3_train_recall_score  \\\n",
       "0                    0.627119                   0.548023   \n",
       "1                    0.683616                   0.627119   \n",
       "2                    0.740113                   0.683616   \n",
       "3                    0.785311                   0.706215   \n",
       "4                    0.824859                   0.740113   \n",
       "5                    0.841808                   0.768362   \n",
       "6                    0.847458                   0.802260   \n",
       "7                    0.847458                   0.813559   \n",
       "8                    0.847458                   0.824859   \n",
       "9                    0.853107                   0.830508   \n",
       "10                   0.858757                   0.841808   \n",
       "11                   0.858757                   0.841808   \n",
       "12                   0.870056                   0.841808   \n",
       "13                   0.870056                   0.841808   \n",
       "14                   0.870056                   0.841808   \n",
       "15                   0.870056                   0.841808   \n",
       "16                   0.870056                   0.841808   \n",
       "17                   0.875706                   0.853107   \n",
       "18                   0.881356                   0.853107   \n",
       "19                   0.881356                   0.858757   \n",
       "20                   0.881356                   0.858757   \n",
       "21                   0.881356                   0.858757   \n",
       "22                   0.881356                   0.858757   \n",
       "23                   0.881356                   0.858757   \n",
       "24                   0.881356                   0.858757   \n",
       "25                   0.881356                   0.864407   \n",
       "26                   0.881356                   0.864407   \n",
       "27                   0.881356                   0.864407   \n",
       "28                   0.881356                   0.864407   \n",
       "29                   0.881356                   0.864407   \n",
       "\n",
       "    split4_train_recall_score  split5_train_recall_score  \\\n",
       "0                    0.573864                   0.573864   \n",
       "1                    0.670455                   0.647727   \n",
       "2                    0.710227                   0.698864   \n",
       "3                    0.744318                   0.732955   \n",
       "4                    0.755682                   0.744318   \n",
       "5                    0.778409                   0.789773   \n",
       "6                    0.789773                   0.818182   \n",
       "7                    0.829545                   0.829545   \n",
       "8                    0.846591                   0.835227   \n",
       "9                    0.846591                   0.835227   \n",
       "10                   0.852273                   0.840909   \n",
       "11                   0.857955                   0.846591   \n",
       "12                   0.857955                   0.846591   \n",
       "13                   0.857955                   0.846591   \n",
       "14                   0.857955                   0.852273   \n",
       "15                   0.857955                   0.852273   \n",
       "16                   0.863636                   0.852273   \n",
       "17                   0.869318                   0.852273   \n",
       "18                   0.869318                   0.852273   \n",
       "19                   0.869318                   0.857955   \n",
       "20                   0.875000                   0.857955   \n",
       "21                   0.875000                   0.857955   \n",
       "22                   0.875000                   0.863636   \n",
       "23                   0.875000                   0.863636   \n",
       "24                   0.875000                   0.863636   \n",
       "25                   0.875000                   0.863636   \n",
       "26                   0.875000                   0.863636   \n",
       "27                   0.875000                   0.875000   \n",
       "28                   0.875000                   0.875000   \n",
       "29                   0.875000                   0.875000   \n",
       "\n",
       "    split6_train_recall_score  split7_train_recall_score  \\\n",
       "0                    0.562500                   0.613636   \n",
       "1                    0.630682                   0.687500   \n",
       "2                    0.687500                   0.715909   \n",
       "3                    0.715909                   0.755682   \n",
       "4                    0.727273                   0.778409   \n",
       "5                    0.772727                   0.789773   \n",
       "6                    0.801136                   0.801136   \n",
       "7                    0.812500                   0.806818   \n",
       "8                    0.823864                   0.829545   \n",
       "9                    0.829545                   0.835227   \n",
       "10                   0.835227                   0.835227   \n",
       "11                   0.835227                   0.846591   \n",
       "12                   0.835227                   0.852273   \n",
       "13                   0.835227                   0.863636   \n",
       "14                   0.835227                   0.863636   \n",
       "15                   0.835227                   0.863636   \n",
       "16                   0.840909                   0.863636   \n",
       "17                   0.840909                   0.869318   \n",
       "18                   0.846591                   0.869318   \n",
       "19                   0.852273                   0.869318   \n",
       "20                   0.852273                   0.869318   \n",
       "21                   0.852273                   0.869318   \n",
       "22                   0.852273                   0.869318   \n",
       "23                   0.852273                   0.869318   \n",
       "24                   0.852273                   0.869318   \n",
       "25                   0.852273                   0.869318   \n",
       "26                   0.852273                   0.869318   \n",
       "27                   0.857955                   0.869318   \n",
       "28                   0.857955                   0.869318   \n",
       "29                   0.857955                   0.869318   \n",
       "\n",
       "    split8_train_recall_score  split9_train_recall_score  \\\n",
       "0                    0.636364                   0.607955   \n",
       "1                    0.698864                   0.687500   \n",
       "2                    0.744318                   0.727273   \n",
       "3                    0.772727                   0.738636   \n",
       "4                    0.784091                   0.761364   \n",
       "5                    0.795455                   0.772727   \n",
       "6                    0.818182                   0.789773   \n",
       "7                    0.835227                   0.818182   \n",
       "8                    0.857955                   0.829545   \n",
       "9                    0.863636                   0.846591   \n",
       "10                   0.863636                   0.846591   \n",
       "11                   0.869318                   0.852273   \n",
       "12                   0.869318                   0.857955   \n",
       "13                   0.869318                   0.857955   \n",
       "14                   0.869318                   0.857955   \n",
       "15                   0.875000                   0.857955   \n",
       "16                   0.880682                   0.863636   \n",
       "17                   0.880682                   0.863636   \n",
       "18                   0.886364                   0.863636   \n",
       "19                   0.886364                   0.863636   \n",
       "20                   0.886364                   0.863636   \n",
       "21                   0.886364                   0.863636   \n",
       "22                   0.886364                   0.863636   \n",
       "23                   0.886364                   0.869318   \n",
       "24                   0.886364                   0.869318   \n",
       "25                   0.886364                   0.875000   \n",
       "26                   0.892045                   0.875000   \n",
       "27                   0.897727                   0.875000   \n",
       "28                   0.897727                   0.875000   \n",
       "29                   0.897727                   0.875000   \n",
       "\n",
       "    mean_train_recall_score  std_train_recall_score  \n",
       "0                  0.612185                0.054733  \n",
       "1                  0.680239                0.050286  \n",
       "2                  0.724454                0.043881  \n",
       "3                  0.749978                0.039589  \n",
       "4                  0.771498                0.037959  \n",
       "5                  0.792485                0.029289  \n",
       "6                  0.812327                0.021063  \n",
       "7                  0.827080                0.017190  \n",
       "8                  0.838431                0.013974  \n",
       "9                  0.844665                0.012015  \n",
       "10                 0.848064                0.010502  \n",
       "11                 0.852038                0.009997  \n",
       "12                 0.854305                0.011103  \n",
       "13                 0.855441                0.011414  \n",
       "14                 0.856009                0.011097  \n",
       "15                 0.856577                0.011881  \n",
       "16                 0.859415                0.011778  \n",
       "17                 0.862811                0.011843  \n",
       "18                 0.864513                0.012530  \n",
       "19                 0.866214                0.010798  \n",
       "20                 0.866782                0.011092  \n",
       "21                 0.867347                0.010509  \n",
       "22                 0.867915                0.010133  \n",
       "23                 0.868484                0.010036  \n",
       "24                 0.868484                0.010036  \n",
       "25                 0.869617                0.009789  \n",
       "26                 0.870185                0.010851  \n",
       "27                 0.872458                0.011025  \n",
       "28                 0.872458                0.011025  \n",
       "29                 0.873588                0.010104  \n",
       "\n",
       "[30 rows x 56 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23fe3b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "for score in ['mean_test_recall_score', 'mean_test_precision']:\n",
    "    plt.plot([_[1] for _ in df['param_class_weight']], \n",
    "             df[score], \n",
    "             label=score)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ab7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below code was used to find whether there was even a mean_test_recall column. I found that it was not even there in the first case which was giving a key error message.\n",
    "#fixed it by just using the mean_test_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24ecdd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_class_weight', 'params', 'split0_test_precision',\n",
      "       'split1_test_precision', 'split2_test_precision',\n",
      "       'split3_test_precision', 'split4_test_precision',\n",
      "       'split5_test_precision', 'split6_test_precision',\n",
      "       'split7_test_precision', 'split8_test_precision',\n",
      "       'split9_test_precision', 'mean_test_precision', 'std_test_precision',\n",
      "       'rank_test_precision', 'split0_train_precision',\n",
      "       'split1_train_precision', 'split2_train_precision',\n",
      "       'split3_train_precision', 'split4_train_precision',\n",
      "       'split5_train_precision', 'split6_train_precision',\n",
      "       'split7_train_precision', 'split8_train_precision',\n",
      "       'split9_train_precision', 'mean_train_precision', 'std_train_precision',\n",
      "       'split0_test_recall_score', 'split1_test_recall_score',\n",
      "       'split2_test_recall_score', 'split3_test_recall_score',\n",
      "       'split4_test_recall_score', 'split5_test_recall_score',\n",
      "       'split6_test_recall_score', 'split7_test_recall_score',\n",
      "       'split8_test_recall_score', 'split9_test_recall_score',\n",
      "       'mean_test_recall_score', 'std_test_recall_score',\n",
      "       'rank_test_recall_score', 'split0_train_recall_score',\n",
      "       'split1_train_recall_score', 'split2_train_recall_score',\n",
      "       'split3_train_recall_score', 'split4_train_recall_score',\n",
      "       'split5_train_recall_score', 'split6_train_recall_score',\n",
      "       'split7_train_recall_score', 'split8_train_recall_score',\n",
      "       'split9_train_recall_score', 'mean_train_recall_score',\n",
      "       'std_train_recall_score'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mean_test_recall'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_test_recall'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_recall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_precision\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot([_[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_class_weight\u001b[39m\u001b[38;5;124m'\u001b[39m]], \n\u001b[1;32m----> 9\u001b[0m              \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m]\u001b[49m, \n\u001b[0;32m     10\u001b[0m              label\u001b[38;5;241m=\u001b[39mscore)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_test_recall'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# Print the column names to check for correctness\n",
    "print(df.columns)\n",
    "\n",
    "for score in ['mean_test_recall', 'mean_test_precision']:\n",
    "    plt.plot([_[1] for _ in df['param_class_weight']], \n",
    "             df[score], \n",
    "             label=score)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25bca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "for score in ['mean_train_recall', 'mean_train_precision']:\n",
    "    plt.scatter(x=[_[1] for _ in df['param_class_weight']],\n",
    "               y=df[score.replace('test', 'train')],\n",
    "               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
