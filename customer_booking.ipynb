{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34378c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945124b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       num_passengers sales_channel  trip_type  purchase_lead  length_of_stay  \\\n",
      "0                   2      Internet  RoundTrip            262              19   \n",
      "1                   1      Internet  RoundTrip            112              20   \n",
      "2                   2      Internet  RoundTrip            243              22   \n",
      "3                   1      Internet  RoundTrip             96              31   \n",
      "4                   2      Internet  RoundTrip             68              22   \n",
      "...               ...           ...        ...            ...             ...   \n",
      "49995               2      Internet  RoundTrip             27               6   \n",
      "49996               1      Internet  RoundTrip            111               6   \n",
      "49997               1      Internet  RoundTrip             24               6   \n",
      "49998               1      Internet  RoundTrip             15               6   \n",
      "49999               1      Internet  RoundTrip             19               6   \n",
      "\n",
      "       flight_hour flight_day   route booking_origin  wants_extra_baggage  \\\n",
      "0                7        Sat  AKLDEL    New Zealand                    1   \n",
      "1                3        Sat  AKLDEL    New Zealand                    0   \n",
      "2               17        Wed  AKLDEL          India                    1   \n",
      "3                4        Sat  AKLDEL    New Zealand                    0   \n",
      "4               15        Wed  AKLDEL          India                    1   \n",
      "...            ...        ...     ...            ...                  ...   \n",
      "49995            9        Sat  PERPNH      Australia                    1   \n",
      "49996            4        Sun  PERPNH      Australia                    0   \n",
      "49997           22        Sat  PERPNH      Australia                    0   \n",
      "49998           11        Mon  PERPNH      Australia                    1   \n",
      "49999           10        Thu  PERPNH      Australia                    0   \n",
      "\n",
      "       wants_preferred_seat  wants_in_flight_meals  flight_duration  \\\n",
      "0                         0                      0             5.52   \n",
      "1                         0                      0             5.52   \n",
      "2                         1                      0             5.52   \n",
      "3                         0                      1             5.52   \n",
      "4                         0                      1             5.52   \n",
      "...                     ...                    ...              ...   \n",
      "49995                     0                      1             5.62   \n",
      "49996                     0                      0             5.62   \n",
      "49997                     0                      1             5.62   \n",
      "49998                     0                      1             5.62   \n",
      "49999                     1                      0             5.62   \n",
      "\n",
      "       booking_complete  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n",
      "...                 ...  \n",
      "49995                 0  \n",
      "49996                 0  \n",
      "49997                 0  \n",
      "49998                 0  \n",
      "49999                 0  \n",
      "\n",
      "[50000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('customer_booking.csv', encoding='latin-1')[:80_000]\n",
    "print(dataset)\n",
    "dataset.shape\n",
    "X = dataset.drop(columns=['sales_channel', 'trip_type', 'flight_hour', 'flight_day', 'route', 'booking_origin']).values\n",
    "y = dataset['booking_complete'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec92a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "472dc8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4af0dd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.     3.     5.   ...   0.     8.15   0.  ]\n",
      " [  1.    39.   195.   ...   1.     8.58   0.  ]\n",
      " [  2.   138.     4.   ...   0.     4.67   0.  ]\n",
      " ...\n",
      " [  2.   115.     6.   ...   1.     8.67   0.  ]\n",
      " [  1.    14.     6.   ...   0.     7.     0.  ]\n",
      " [  1.   341.    85.   ...   1.     8.83   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train) #X_train dataset containg 300 observation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aff517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train) #y_train dataset containg 300 observation for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdcf3cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.    33.    20.   ...   1.     8.83   0.  ]\n",
      " [  1.   115.   137.   ...   0.     8.83   1.  ]\n",
      " [  1.    14.     6.   ...   0.     6.42   0.  ]\n",
      " ...\n",
      " [  1.    10.     5.   ...   0.     4.67   0.  ]\n",
      " [  1.    28.     4.   ...   0.     8.58   0.  ]\n",
      " [  1.    43.    39.   ...   1.     8.58   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)  #X_test dataset containg 100 observation for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ab0e189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)  #y_test dataset containg 100 observation for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c12eadf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28fc85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c799f6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.57985996 -0.906049   -0.53320986 ... -0.86558093  0.57954646\n",
      "  -0.41836934]\n",
      " [-0.57985996 -0.50890114  5.08209729 ...  1.15529348  0.86638539\n",
      "  -0.41836934]\n",
      " [ 0.40384275  0.58325546 -0.56276411 ... -0.86558093 -1.74184769\n",
      "  -0.41836934]\n",
      " ...\n",
      " [ 0.40384275  0.32952211 -0.50365562 ...  1.15529348  0.92642144\n",
      "  -0.41836934]\n",
      " [-0.57985996 -0.78469827 -0.50365562 ... -0.86558093 -0.18758092\n",
      "  -0.41836934]\n",
      " [-0.57985996  2.82272809  1.83112999 ...  1.15529348  1.03315221\n",
      "  -0.41836934]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)  #X_train dataset containg 300 observation for training after Feature Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0bf2dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.40384275 -0.57509245 -0.08989614 ...  1.15529348  1.03315221\n",
      "  -0.41836934]\n",
      " [-0.57985996  0.32952211  3.3679509  ... -0.86558093  1.03315221\n",
      "   2.39023254]\n",
      " [-0.57985996 -0.78469827 -0.50365562 ... -0.86558093 -0.57447995\n",
      "  -0.41836934]\n",
      " ...\n",
      " [-0.57985996 -0.82882581 -0.53320986 ... -0.86558093 -1.74184769\n",
      "  -0.41836934]\n",
      " [-0.57985996 -0.63025188 -0.56276411 ... -0.86558093  0.86638539\n",
      "  -0.41836934]\n",
      " [-0.57985996 -0.4647736   0.47163457 ...  1.15529348  0.86638539\n",
      "   2.39023254]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)  #X_test dataset containg 300 observation for testing after Feature Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "061d57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Logistic Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a47cb72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3789df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting a new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f19bc112",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but StandardScaler is expecting 8 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(classifier\u001b[38;5;241m.\u001b[39mpredict(\u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m87000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:992\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    989\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    991\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m--> 992\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features, but StandardScaler is expecting 8 features as input."
     ]
    }
   ],
   "source": [
    "print(classifier.predict(sc.transform([[30,87000]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba055c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
